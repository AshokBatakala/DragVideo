{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def align_faces_2(root_path):\n",
    "    import os \n",
    "    current_path = os.getcwd()\n",
    "    temp_path = \"/home/bean/stylegan3-editing\"\n",
    "    os.chdir(temp_path)\n",
    "    command =f\"\"\"python prepare_data/preparing_faces_parallel.py \\\n",
    "                --mode align \\\n",
    "                --root_path  {root_path} \n",
    "                \"\"\"\n",
    "    import subprocess\n",
    "    subprocess.run(command, shell=True)\n",
    "    os.chdir(current_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DRAGVIDEO_ROOT_PATH = \"/Ext_4T_SSD/ASHOK/\"\n",
    "DRAGVIDEO_ROOT_PATH = \"/home/bean/\"\n",
    "\n",
    "# keep matching encoder,SG as pairt \n",
    "old = {\"encoder\":  f\"{DRAGVIDEO_ROOT_PATH}DragVideo/DragGAN/_PTI/pretrained_models/e4e_ffhq_encode.pt\",\n",
    "       \"SG\": f\"{DRAGVIDEO_ROOT_PATH}DragVideo/DragGAN/_PTI/pretrained_models/ffhq.pkl\",\n",
    "       \"model_name\":\"stylegan2\",\n",
    "       \"resolution\":1024,\n",
    "       }\n",
    "\n",
    "new = {\"encoder\": f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/OLD/model_weights/restyle_e4e_ffhq.pt\",\n",
    "         \"SG\":  f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/OLD/model_weights/stylegan3_3rdtime_weights/stylegan3-r-ffhq-1024_module.pkl\",\n",
    "         \"model_name\":\"stylegan3\",\n",
    "               \"resolution\":1024,\n",
    "         }\n",
    "\n",
    "new_256 = {\"encoder\": f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/OLD/model_weights/restyle_e4e_ffhq.pt\",\n",
    "         \"SG\":  f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/OLD/Stylegan3_1_files/stylegan3-r-ffhqu-256x256.pkl\",\n",
    "         \"model_name\":\"stylegan3\",\n",
    "         \"resolution\":256,\n",
    "         }\n",
    "\n",
    "videos = {\n",
    "       \"obama\": f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/OLD/original_videos/obama.mp4\",\n",
    "       \"man_speaking\": f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/OLD/original_videos/person_speaking_original.mp4\",\n",
    "       \"rahul\": f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/OLD/original_videos/rahul.mp4\",\n",
    "       \"alien_girl\": f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/OLD/original_videos/alien_girl.mp4\",\n",
    "       \"mirrAR\": f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/OLD/original_videos/mirrAR.mp4\",\n",
    "       \"vsauce_frnd\":f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/OLD/original_videos/micheal_friendzone.mp4\",\n",
    "       \"actress_tan\": f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/OLD/original_videos/gadot_tanned_left.mp4\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME_POSTFIX = \"actress_smile\"#\"aligned_sg3_&_new_e4e_reconstruction_invstep_200_pti_step_450\"\n",
    "models_set = old\n",
    "Testing =True\n",
    "# --------------------------------  \n",
    "\n",
    "\n",
    "import datetime\n",
    "lazy_config = {\n",
    "    \n",
    "    #-----------------\n",
    "    # often changed\n",
    "    #-----------------\n",
    "    \"video_path\":  videos[\"actress_tan\"],\n",
    "    \"n_frames\" : 150,#120,#200,\n",
    "    \"N_STEPS_in_draggan\":  \"150\",\n",
    "    \"editing_function_name\":\"smile\", #\"smile\",#\"large_eyes\",#\"large_eyes\" # \"make_jaw_wider\" # \"mouth_wide\",\"up_eyebrows\"\n",
    "        \n",
    "    # less often changed\n",
    "    \"EXP_NAME\": str(datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))+\"_\"+ EXPERIMENT_NAME_POSTFIX,\n",
    "    \"e4e\": models_set['encoder'],\n",
    "    \"stylegan2_ada_ffhq\": models_set['SG'],\n",
    "    \"model_name\" : models_set['model_name'],\n",
    "    \"IMAGE_SIZE\": models_set[\"resolution\"],\n",
    "    \"fps\": 24,\n",
    "    \n",
    "}\n",
    "\n",
    "env_config = {\n",
    "    \"DragGAN_dir\": f\"{DRAGVIDEO_ROOT_PATH}DragVideo/DragGAN\",\n",
    "    \"Experiment_base_path\":f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/experiments/\" ,\n",
    "    \"init_exp_dir_shell_path\": f\"{DRAGVIDEO_ROOT_PATH}DragVideo/DragGAN/_PTI/init_datadirs.sh\",\n",
    "    \"dummy_config_path\" : f\"{DRAGVIDEO_ROOT_PATH}DragVideo/DragGAN/_PTI/configs/dummy\",\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "#hyper parameters in PTI\n",
    "\n",
    "hyper_config = {\n",
    "    \"max_pti_steps\": 350,\n",
    "    \"first_inv_steps\":450,\n",
    "    \"max_images_to_invert\": 200,\n",
    "}\n",
    "\n",
    "if Testing: \n",
    "    hyper_config[\"max_pti_steps\"] = 200\n",
    "    hyper_config[\"first_inv_steps\"] = 350\n",
    "    hyper_config[\"max_images_to_invert\"] = 5\n",
    "    lazy_config[\"N_STEPS_in_draggan\"] = '150'\n",
    "    lazy_config[\"n_frames\"] = 1\n",
    "    lazy_config[\"editing_function_name\"]=\"smile\"\n",
    "    \n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# create experiment data folder structure\n",
    "Experiment_name = lazy_config[\"EXP_NAME\"]\n",
    "Experiment_base_path = env_config[\"Experiment_base_path\"]\n",
    "Experiment_path = os.path.join(Experiment_base_path, Experiment_name)\n",
    "\n",
    "# change path configs , hyperparameters \n",
    "paths_config_dict = {\n",
    "    #pretrained models\n",
    "    \"e4e\": lazy_config[\"e4e\"],\n",
    "    \"stylegan2_ada_ffhq\": lazy_config[\"stylegan2_ada_ffhq\"],\n",
    "    \n",
    "    # to store tuned stylegan weights\n",
    "    \"checkpoints_dir\": os.path.join(Experiment_path,'tuned_SG'),\n",
    "    # to store latents\n",
    "    \"embedding_base_dir\": os.path.join(Experiment_path,'latents'),\n",
    "    # aligned / processed images\n",
    "    \"input_data_path\": os.path.join(Experiment_path,'aligned'),\n",
    "     \"quad_values_path\": os.path.join(Experiment_path,'quad_values'),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_utils import *\n",
    "\n",
    "init_experiment_dir(Experiment_name,Experiment_base_path,shell_script_path=env_config[\"init_exp_dir_shell_path\"])\n",
    "\n",
    "# dummy paths_config overwrites the paths_config.py\n",
    "# dummy_config_path = f\"{DRAGVIDEO_ROOT_PATH}DragVideo/DragGAN/_PTI/configs/dummy'\n",
    "add_dummy_config_from_dict(\"hyperparameters.py\", hyper_config,ROOT_PATH=env_config[\"dummy_config_path\"])\n",
    "\n",
    "add_dummy_config_from_dict(\"paths_config.py\", paths_config_dict,ROOT_PATH=env_config[\"dummy_config_path\"])\n",
    "\n",
    "\n",
    "\n",
    "# add all these configs to log.txt\n",
    "# --------------------------------  \n",
    "with open(os.path.join(Experiment_path,'log.txt'), 'a') as f:\n",
    "    import json\n",
    "    f.write(f\"lazy_config: {json.dumps(lazy_config, indent=4)}\\n\")\n",
    "    f.write(f\"env_config: {json.dumps(env_config, indent=4)}\\n\")\n",
    "    f.write(f\"hyper_config: {json.dumps(hyper_config, indent=4)}\\n\")\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.0.2 Copyright (c) 2000-2018 the FFmpeg developers\n",
      "  built with gcc 4.8.2 (GCC) 20140120 (Red Hat 4.8.2-15)\n",
      "  configuration: --prefix=/home/conda/feedstock_root/build_artifacts/ffmpeg_1539667330082/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --disable-doc --disable-openssl --enable-shared --enable-static --extra-cflags='-Wall -g -m64 -pipe -O3 -march=x86-64 -fPIC' --extra-cxxflags='-Wall -g -m64 -pipe -O3 -march=x86-64 -fPIC' --extra-libs='-lpthread -lm -lz' --enable-zlib --enable-pic --enable-pthreads --enable-gpl --enable-version3 --enable-hardcoded-tables --enable-avresample --enable-libfreetype --enable-gnutls --enable-libx264 --enable-libopenh264\n",
      "  libavutil      56. 14.100 / 56. 14.100\n",
      "  libavcodec     58. 18.100 / 58. 18.100\n",
      "  libavformat    58. 12.100 / 58. 12.100\n",
      "  libavdevice    58.  3.100 / 58.  3.100\n",
      "  libavfilter     7. 16.100 /  7. 16.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  1.100 /  5.  1.100\n",
      "  libswresample   3.  1.100 /  3.  1.100\n",
      "  libpostproc    55.  1.100 / 55.  1.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/home/bean/DragVideo/Data_store/OLD/original_videos/gadot_tanned_left.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.12.100\n",
      "  Duration: 00:00:08.20, start: 0.000000, bitrate: 1434 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1024x1024, 1430 kb/s, 30 fps, 30 tbr, 15360 tbn, 60 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> png (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, image2, to '/home/bean/DragVideo/Data_store/experiments/2023-09-06_00-38-36_actress_smile/raw/%03d.png':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.12.100\n",
      "    Stream #0:0(und): Video: png, rgb24, 1024x1024, q=2-31, 200 kb/s, 24 fps, 24 tbn, 24 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      encoder         : Lavc58.18.100 png\n",
      "frame=    1 fps=0.0 q=-0.0 Lsize=N/A time=00:00:00.04 bitrate=N/A speed=0.613x    \n",
      "video:496kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n"
     ]
    }
   ],
   "source": [
    "# extract frames from video\n",
    "#==============================================================================\n",
    "\n",
    "from importlib.machinery import SourceFileLoader\n",
    "# imports the module from the given path\n",
    "# video_utils = SourceFileLoader(\"video_utils\",\"../utils_draggan/video_utils.py\").load_module()\n",
    "\n",
    "ffmpeg_utils = SourceFileLoader(\"video_utils\",\"../utils_draggan/ffmpeg_utils.py\").load_module()\n",
    "raw_path = os.path.join(Experiment_path, \"raw\")\n",
    "\n",
    "# # video_utils.extract_frames(lazy_config['video_path'], raw_path,n_frames=lazy_config['n_frames'])\n",
    "ffmpeg_utils.ffmpeg.extract_frames(video_path = lazy_config['video_path'],\n",
    "                                      output_frames_dir = raw_path,\n",
    "                                      fps = lazy_config['fps'],\n",
    "                                      first_n_frames = lazy_config['n_frames'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # delete this cell \n",
    "# # \"/home/bean/DragVideo/Data_store/man_speaking/aligned\": input_data_path \n",
    "# # \"/home/bean/DragVideo/Data_store/man_speaking/quad_values\", quad_pkl_path\n",
    "\n",
    "# raw_path = \"/home/bean/DragVideo/Data_store/man_speaking/raw\"\n",
    "# pre_process_images(raw_path, IMAGE_SIZE=1024) # o/p: config.input_data_path ,quad pickle dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving aligned images...\n",
      "saving quad values...\n",
      "done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.align_data import pre_process_images\n",
    "pre_process_images(raw_path, IMAGE_SIZE=lazy_config['IMAGE_SIZE']) # o/p: config.input_data_path ,quad pickle dir\n",
    "#\n",
    "# align_faces_2(os.path.join(Experiment_path,'raw'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bean/.conda/envs/stylegan3/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/bean/.conda/envs/stylegan3/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bean/.conda/envs/stylegan3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/bean/.conda/envs/stylegan3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/bean/.conda/envs/stylegan3/lib/python3.9/site-packages/lpips/weights/v0.1/alex.pth\n",
      "current_directory:  /home/bean/DragVideo/DragGAN/_PTI\n",
      "current_directory:  /home/bean/DragVideo/DragGAN/_PTI\n",
      "torch.Size([3, 1024, 1024]) 3 1024 1024\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bean/.conda/envs/stylegan3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501: UserWarning: operator() profile_node %106 : int = prim::profile_ivalue(%104)\n",
      " does not have profile information (Triggered internally at /opt/conda/conda-bld/pytorch_1682343964576/work/third_party/nvfuser/csrc/graph_fuser.cpp:104.)\n",
      "  return forward_call(*args, **kwargs)\n",
      "100%|██████████| 350/350 [00:29<00:00, 11.75it/s]\n",
      "100%|██████████| 200/200 [00:15<00:00, 13.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting large updated pickle based off new generator and ffhq.pkl\n",
      "pwd /home/bean/DragVideo/DragGAN/_facial-landmarks-recognition\n",
      "landmark_path:  /home/bean/DragVideo/Data_store/experiments/2023-09-06_00-38-36_actress_smile/landmarks/000.pkl\n"
     ]
    }
   ],
   "source": [
    "from utils.align_data import pre_process_images\n",
    "from scripts.run_pti import run_PTI\n",
    "\n",
    "from run_utils_2 import load_generators,export_updated_pickle\n",
    "from configs import paths_config\n",
    "\n",
    "use_multi_id_training = True\n",
    "model_id = run_PTI(use_wandb=False, use_multi_id_training=use_multi_id_training)\n",
    "\n",
    "generator_type =paths_config.multi_id_model_type if use_multi_id_training else \"__\"\n",
    "old_G, new_G = load_generators(model_id, generator_type)\n",
    "sg_tuned_pkl = export_updated_pickle(new_G,model_id,name = lazy_config[\"model_name\"])\n",
    "\n",
    "# print(sg_tuned_pkl) # 'QBUXQCXZGWET'\n",
    "\n",
    "\n",
    "\n",
    "#get landmarks\n",
    "landmark_path = f\"{DRAGVIDEO_ROOT_PATH}DragVideo/DragGAN/_facial-landmarks-recognition\"\n",
    "os.chdir(landmark_path)\n",
    "print(\"pwd\",os.getcwd())\n",
    "import sys\n",
    "sys.path.append(landmark_path)\n",
    "\n",
    "from main import landmarks, dict_landmarks,show_landmarks,get_landmarks_dir\n",
    "\n",
    "# to store landmarks\n",
    "landmarks_dir =  os.path.join(Experiment_path,'landmarks')\n",
    "processed_images_dir =  os.path.join(Experiment_path,'aligned')\n",
    "\n",
    "# generate landmarks for all images in processed_images_dir\n",
    "get_landmarks_dir(processed_images_dir,landmarks_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runs draggan \n",
    "all the the below cells use only these config values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util function to copy an experiment dir\n",
    "def copy_exp_dir(exp_src):\n",
    "    import shutil\n",
    "    exp_dst = exp_src+\"_copy\"\n",
    "    shutil.copytree(exp_src, exp_dst)\n",
    "    return exp_dst\n",
    "    \n",
    "# copy_exp_dir(\"/home/bean/DragVideo/Data_store/experiments/_SAVE_vsauce_ffmpeg_untuned_sg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Run first config cells, then run this\n",
    "# if True:\n",
    "#     # just to run draggan seperately\n",
    "#     import os \n",
    "#     a = \"/home/bean/DragVideo/Data_store/experiments/sept_1\"\n",
    "#     b = \"/home/bean/DragVideo/Data_store/experiments/sept_1/tuned_SG/stylegan3_NXHOAZADQKTA.pkl\"\n",
    "    \n",
    "#     Experiment_path = a# f\"/home/bean/DragVideo/Data_store/experiments/{lazy_config['EXP_NAME']}\"\t\n",
    "#     sg_tuned_pkl = b #new[\"SG\"]\n",
    "\n",
    "\n",
    "#     lazy_config[\"N_STEPS_in_draggan\"]=\"150\"\n",
    "#     lazy_config[\"editing_function_name\"]= \"smile\"#\"make_jaw_wider\"#smile\"\n",
    "#     lazy_config[\"IMAGE_SIZE\"]=\"1024\"\n",
    "\n",
    "# # /home/bean/DragVideo/Data_store/experiments/sept_1/latents/0.pt\n",
    "# # /home/bean/DragVideo/Data_store/experiments/_SAVE_vsauce_frnd_120_frames_wide_nose_with_border/latents/barcelona/PTI/000/0.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lazy_config[\"N_STEPS_in_draggan\"]=\"150\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sg_tuned_pkl: /home/bean/DragVideo/Data_store/experiments/2023-09-06_00-38-36_actress_smile/tuned_SG/stylegan2_BQBQPVLELWMW.pkl\n",
      "editing_function_name: smile\n",
      "Total 1 images to be processed\n",
      "intiating global state....\n",
      "calling init_images......\n",
      "Loading \"/home/bean/DragVideo/Data_store/experiments/2023-09-06_00-38-36_actress_smile/tuned_SG/stylegan2_BQBQPVLELWMW.pkl\"... Done.\n",
      "()\n",
      "{'z_dim': 512, 'c_dim': 0, 'w_dim': 512, 'img_resolution': 1024, 'img_channels': 3, 'mapping_kwargs': {'num_layers': 8, 'embed_features': None, 'layer_features': None, 'activation': 'lrelu', 'lr_multiplier': 0.01, 'w_avg_beta': 0.995}, 'synthesis_kwargs': {'channel_base': 32768, 'channel_max': 512, 'num_fp16_res': 4, 'conv_clamp': 256, 'architecture': 'skip', 'resample_filter': [1, 3, 3, 1], 'use_noise': True, 'activation': 'lrelu'}}\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s]/home/bean/.conda/envs/stylegan3/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343964576/work/aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "  1%|          | 1/150 [00:00<00:56,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 2/150 [00:00<00:46,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/150 [00:00<00:42,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/150 [00:01<00:41,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 5/150 [00:01<00:40,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 6/150 [00:01<00:39,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 7/150 [00:01<00:38,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 8/150 [00:02<00:38,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 9/150 [00:02<00:37,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 10/150 [00:02<00:37,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 11/150 [00:03<00:37,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 12/150 [00:03<00:36,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 13/150 [00:03<00:36,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 14/150 [00:03<00:36,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 15/150 [00:04<00:35,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 16/150 [00:04<00:35,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 17/150 [00:04<00:35,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 18/150 [00:04<00:35,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 19/150 [00:05<00:35,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 20/150 [00:05<00:34,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 21/150 [00:05<00:34,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 22/150 [00:05<00:34,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 23/150 [00:06<00:33,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 24/150 [00:06<00:33,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 25/150 [00:06<00:33,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 26/150 [00:07<00:33,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 27/150 [00:07<00:33,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 28/150 [00:07<00:32,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 29/150 [00:07<00:32,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 30/150 [00:08<00:32,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 31/150 [00:08<00:32,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 32/150 [00:08<00:31,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 33/150 [00:08<00:31,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 34/150 [00:09<00:31,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 35/150 [00:09<00:30,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 36/150 [00:09<00:30,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 37/150 [00:10<00:30,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 38/150 [00:10<00:29,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 39/150 [00:10<00:29,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 40/150 [00:10<00:29,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 41/150 [00:11<00:29,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 42/150 [00:11<00:28,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 43/150 [00:11<00:28,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 44/150 [00:11<00:28,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 45/150 [00:12<00:27,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 46/150 [00:12<00:27,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 47/150 [00:12<00:27,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 48/150 [00:12<00:27,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 49/150 [00:13<00:27,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 50/150 [00:13<00:26,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 51/150 [00:13<00:26,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 52/150 [00:14<00:26,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 53/150 [00:14<00:25,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 54/150 [00:14<00:25,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 55/150 [00:14<00:25,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 56/150 [00:15<00:25,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 57/150 [00:15<00:24,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 58/150 [00:15<00:24,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 59/150 [00:15<00:24,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 60/150 [00:16<00:24,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 61/150 [00:16<00:23,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 62/150 [00:16<00:23,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 63/150 [00:16<00:23,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 64/150 [00:17<00:22,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 66/150 [00:17<00:18,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 68/150 [00:17<00:13,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 70/150 [00:18<00:10,  7.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 72/150 [00:18<00:09,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 74/150 [00:18<00:08,  8.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 76/150 [00:18<00:08,  8.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 78/150 [00:18<00:07,  9.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 80/150 [00:19<00:07,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 82/150 [00:19<00:07,  9.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 84/150 [00:19<00:07,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 86/150 [00:19<00:06,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 88/150 [00:19<00:06,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 90/150 [00:20<00:06,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 92/150 [00:20<00:06,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 94/150 [00:20<00:06,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 96/150 [00:20<00:05,  9.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 98/150 [00:21<00:05,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 99/150 [00:21<00:08,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 100/150 [00:21<00:09,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 101/150 [00:21<00:10,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 103/150 [00:22<00:09,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 105/150 [00:22<00:06,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 107/150 [00:22<00:05,  7.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 109/150 [00:22<00:04,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 111/150 [00:23<00:04,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 113/150 [00:23<00:04,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 115/150 [00:23<00:03,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 117/150 [00:23<00:03,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 119/150 [00:23<00:03,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 121/150 [00:24<00:03,  8.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 123/150 [00:24<00:03,  8.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 125/150 [00:24<00:02,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 127/150 [00:24<00:02,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 129/150 [00:25<00:02,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 131/150 [00:25<00:02,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 133/150 [00:25<00:01,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 135/150 [00:25<00:01,  9.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 137/150 [00:25<00:01,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 139/150 [00:26<00:01,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 141/150 [00:26<00:00,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 143/150 [00:26<00:00,  8.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 145/150 [00:26<00:00,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 147/150 [00:27<00:00,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 149/150 [00:27<00:00,  9.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n",
      "drag_mask shape : (torch.Size([1024, 1024]), <class 'torch.Tensor'>, torch.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:27<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean all data from gpu\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "os.chdir(env_config[\"DragGAN_dir\"])\n",
    "import subprocess\n",
    "\n",
    "print(f\"sg_tuned_pkl: {sg_tuned_pkl}\")\n",
    "\n",
    "subprocess.call(['python', '_run_dragvideo.py',\n",
    "                 '--Experiment_path', Experiment_path,\n",
    "                 '--N_STEPS',       lazy_config[\"N_STEPS_in_draggan\"],\n",
    "                 '--CHECKPOINT_PATH', sg_tuned_pkl,\n",
    "                 \"--MAX_SIZE\",      str(lazy_config[\"IMAGE_SIZE\"]),\n",
    "                 \"--editing_function_name\",lazy_config[\"editing_function_name\"],\n",
    "])\n",
    "                #  \"--verbose\",       \"False\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty catched data\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/bean/DragVideo/DragGAN'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "os.getcwd()\n",
    "# import importlib\n",
    "# importlib.reload(ffmpeg_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utils import de_alignment \n",
    "put_back_the_edited_image = de_alignment.put_back_the_edited_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paste_edited_faces_back(dir_path,edited_dir='after_drag',save_dir='after_drag_pasted'):\n",
    "    raw_dir = os.path.join(dir_path,'raw')\n",
    "    edited_dir = os.path.join(dir_path,edited_dir)\n",
    "    quad_dir = os.path.join(dir_path,'quad_values')\n",
    "    save_dir = os.path.join(dir_path,save_dir)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # get names from edited_dir\n",
    "    names = [name.split('.')[0] for name in os.listdir(edited_dir)]\n",
    "    for name in tqdm(names):\n",
    "        raw_image = os.path.join(raw_dir,name+'.png')\n",
    "        edited_image = os.path.join(edited_dir,name+'.png')\n",
    "        quad_path = os.path.join(quad_dir,name+'.pkl')\n",
    "        save_path = os.path.join(save_dir,name+'.png')\n",
    "        put_back_the_edited_image(raw_image,edited_image,quad_path,save_path=save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.87it/s]\n"
     ]
    }
   ],
   "source": [
    "paste_edited_faces_back(Experiment_path,edited_dir=\"before_drag\",save_dir=\"before_drag_pasted\")\n",
    "paste_edited_faces_back(Experiment_path,edited_dir=\"after_drag\",save_dir=\"after_drag_pasted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.0.2 Copyright (c) 2000-2018 the FFmpeg developers\n",
      "  built with gcc 4.8.2 (GCC) 20140120 (Red Hat 4.8.2-15)\n",
      "  configuration: --prefix=/home/conda/feedstock_root/build_artifacts/ffmpeg_1539667330082/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --disable-doc --disable-openssl --enable-shared --enable-static --extra-cflags='-Wall -g -m64 -pipe -O3 -march=x86-64 -fPIC' --extra-cxxflags='-Wall -g -m64 -pipe -O3 -march=x86-64 -fPIC' --extra-libs='-lpthread -lm -lz' --enable-zlib --enable-pic --enable-pthreads --enable-gpl --enable-version3 --enable-hardcoded-tables --enable-avresample --enable-libfreetype --enable-gnutls --enable-libx264 --enable-libopenh264\n",
      "  libavutil      56. 14.100 / 56. 14.100\n",
      "  libavcodec     58. 18.100 / 58. 18.100\n",
      "  libavformat    58. 12.100 / 58. 12.100\n",
      "  libavdevice    58.  3.100 / 58.  3.100\n",
      "  libavfilter     7. 16.100 /  7. 16.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  1.100 /  5.  1.100\n",
      "  libswresample   3.  1.100 /  3.  1.100\n",
      "  libpostproc    55.  1.100 / 55.  1.100\n",
      "Input #0, image2, from './*.png':\n",
      "  Duration: 00:00:00.04, start: 0.000000, bitrate: N/A\n",
      "    Stream #0:0: Video: png, rgb24(pc), 1024x1024, 24 tbr, 24 tbn, 24 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0xcb3400] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0xcb3400] profile High, level 3.2\n",
      "[libx264 @ 0xcb3400] 264 - core 152 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=18 lookahead_threads=3 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=24 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to '/home/bean/DragVideo/Data_store/experiments/2023-09-06_00-38-36_actress_smile/videos/pre_drag_full.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.12.100\n",
      "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 1024x1024, q=-1--1, 24 fps, 12288 tbn, 24 tbc\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.18.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=    1 fps=0.0 q=28.0 Lsize=      15kB time=00:00:00.00 bitrate=1469432.1kbits/s speed=0.00166x    \n",
      "video:14kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 5.682625%\n",
      "[libx264 @ 0xcb3400] frame I:1     Avg QP:23.46  size: 13402\n",
      "[libx264 @ 0xcb3400] mb I  I16..4: 32.8% 66.8%  0.3%\n",
      "[libx264 @ 0xcb3400] 8x8 transform intra:66.8%\n",
      "[libx264 @ 0xcb3400] coded y,uvDC,uvAC intra: 28.5% 56.1% 5.2%\n",
      "[libx264 @ 0xcb3400] i16 v,h,dc,p: 17% 23%  4% 56%\n",
      "[libx264 @ 0xcb3400] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 40% 18% 15%  5%  4%  5%  5%  5%  3%\n",
      "[libx264 @ 0xcb3400] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 37% 13% 20%  5%  8%  7%  4%  5%  1%\n",
      "[libx264 @ 0xcb3400] i8c dc,h,v,p: 48% 17% 26%  9%\n",
      "[libx264 @ 0xcb3400] kb/s:2573.18\n",
      "ffmpeg version 4.0.2 Copyright (c) 2000-2018 the FFmpeg developers\n",
      "  built with gcc 4.8.2 (GCC) 20140120 (Red Hat 4.8.2-15)\n",
      "  configuration: --prefix=/home/conda/feedstock_root/build_artifacts/ffmpeg_1539667330082/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --disable-doc --disable-openssl --enable-shared --enable-static --extra-cflags='-Wall -g -m64 -pipe -O3 -march=x86-64 -fPIC' --extra-cxxflags='-Wall -g -m64 -pipe -O3 -march=x86-64 -fPIC' --extra-libs='-lpthread -lm -lz' --enable-zlib --enable-pic --enable-pthreads --enable-gpl --enable-version3 --enable-hardcoded-tables --enable-avresample --enable-libfreetype --enable-gnutls --enable-libx264 --enable-libopenh264\n",
      "  libavutil      56. 14.100 / 56. 14.100\n",
      "  libavcodec     58. 18.100 / 58. 18.100\n",
      "  libavformat    58. 12.100 / 58. 12.100\n",
      "  libavdevice    58.  3.100 / 58.  3.100\n",
      "  libavfilter     7. 16.100 /  7. 16.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  1.100 /  5.  1.100\n",
      "  libswresample   3.  1.100 /  3.  1.100\n",
      "  libpostproc    55.  1.100 / 55.  1.100\n",
      "Input #0, image2, from './*.png':\n",
      "  Duration: 00:00:00.04, start: 0.000000, bitrate: N/A\n",
      "    Stream #0:0: Video: png, rgb24(pc), 1024x1024, 24 tbr, 24 tbn, 24 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x21c5400] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x21c5400] profile High, level 3.2\n",
      "[libx264 @ 0x21c5400] 264 - core 152 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=18 lookahead_threads=3 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=24 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to '/home/bean/DragVideo/Data_store/experiments/2023-09-06_00-38-36_actress_smile/videos/post_drag_full.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.12.100\n",
      "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 1024x1024, q=-1--1, 24 fps, 12288 tbn, 24 tbc\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.18.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=    1 fps=0.0 q=28.0 Lsize=      15kB time=00:00:00.00 bitrate=1469432.1kbits/s speed=0.0019x    \n",
      "video:14kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 5.682625%\n",
      "[libx264 @ 0x21c5400] frame I:1     Avg QP:23.46  size: 13402\n",
      "[libx264 @ 0x21c5400] mb I  I16..4: 32.8% 66.8%  0.3%\n",
      "[libx264 @ 0x21c5400] 8x8 transform intra:66.8%\n",
      "[libx264 @ 0x21c5400] coded y,uvDC,uvAC intra: 28.5% 56.1% 5.2%\n",
      "[libx264 @ 0x21c5400] i16 v,h,dc,p: 17% 23%  4% 56%\n",
      "[libx264 @ 0x21c5400] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 40% 18% 15%  5%  4%  5%  5%  5%  3%\n",
      "[libx264 @ 0x21c5400] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 37% 13% 20%  5%  8%  7%  4%  5%  1%\n",
      "[libx264 @ 0x21c5400] i8c dc,h,v,p: 48% 17% 26%  9%\n",
      "[libx264 @ 0x21c5400] kb/s:2573.18\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# using ffmpeg to make video\n",
    "# =============================================================================\n",
    "before_drag_pasted_dir = os.path.join(Experiment_path,'before_drag_pasted')\n",
    "after_drag_pasted_dir = os.path.join(Experiment_path,'after_drag_pasted')\n",
    "videos_dir = os.path.join(Experiment_path,'videos')\n",
    "\n",
    "ffmpeg_utils.ffmpeg.make_video(before_drag_pasted_dir,\n",
    "                               video_name=\"pre_drag_full\",\n",
    "                               video_dir=videos_dir,\n",
    "                               fps=lazy_config['fps'],\n",
    "                                 )\n",
    "ffmpeg_utils.ffmpeg.make_video(after_drag_pasted_dir,\n",
    "                                 video_name=\"post_drag_full\",\n",
    "                                    video_dir=videos_dir,\n",
    "                                    fps=lazy_config['fps'],\n",
    "                                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.0.2 Copyright (c) 2000-2018 the FFmpeg developers\n",
      "  built with gcc 4.8.2 (GCC) 20140120 (Red Hat 4.8.2-15)\n",
      "  configuration: --prefix=/home/conda/feedstock_root/build_artifacts/ffmpeg_1539667330082/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --disable-doc --disable-openssl --enable-shared --enable-static --extra-cflags='-Wall -g -m64 -pipe -O3 -march=x86-64 -fPIC' --extra-cxxflags='-Wall -g -m64 -pipe -O3 -march=x86-64 -fPIC' --extra-libs='-lpthread -lm -lz' --enable-zlib --enable-pic --enable-pthreads --enable-gpl --enable-version3 --enable-hardcoded-tables --enable-avresample --enable-libfreetype --enable-gnutls --enable-libx264 --enable-libopenh264\n",
      "  libavutil      56. 14.100 / 56. 14.100\n",
      "  libavcodec     58. 18.100 / 58. 18.100\n",
      "  libavformat    58. 12.100 / 58. 12.100\n",
      "  libavdevice    58.  3.100 / 58.  3.100\n",
      "  libavfilter     7. 16.100 /  7. 16.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  1.100 /  5.  1.100\n",
      "  libswresample   3.  1.100 /  3.  1.100\n",
      "  libpostproc    55.  1.100 / 55.  1.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/home/bean/DragVideo/Data_store/experiments/2023-09-06_00-38-36_actress_smile/videos/pre_drag_full.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.12.100\n",
      "  Duration: 00:00:00.04, start: 0.000000, bitrate: 2833 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1024x1024, 2703 kb/s, 24 fps, 24 tbr, 12288 tbn, 48 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Input #1, mov,mp4,m4a,3gp,3g2,mj2, from '/home/bean/DragVideo/Data_store/experiments/2023-09-06_00-38-36_actress_smile/videos/post_drag_full.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.12.100\n",
      "  Duration: 00:00:00.04, start: 0.000000, bitrate: 2833 kb/s\n",
      "    Stream #1:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1024x1024, 2703 kb/s, 24 fps, 24 tbr, 12288 tbn, 48 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> hstack:input0\n",
      "  Stream #1:0 (h264) -> hstack:input1\n",
      "  hstack -> Stream #0:0 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x25020c0] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x25020c0] profile High, level 4.0\n",
      "[libx264 @ 0x25020c0] 264 - core 152 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=18 lookahead_threads=3 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=24 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to '/home/bean/DragVideo/Data_store/experiments/2023-09-06_00-38-36_actress_smile/videos/hstack_pre_post_drag_full.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.12.100\n",
      "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 2048x1024, q=-1--1, 24 fps, 12288 tbn, 24 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.18.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bean/DragVideo/Data_store/experiments/2023-09-06_00-38-36_actress_smile/videos/hstack_pre_post_drag_full.mp4\n",
      "/home/bean/DragVideo/Data_store/experiments/2023-09-06_00-38-36_actress_smile/videos/hstack_original_post_drag_full.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=    1 fps=0.0 q=28.0 Lsize=      27kB time=00:00:00.00 bitrate=2753580.2kbits/s speed=0.00158x    \n",
      "video:26kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 2.954210%\n",
      "[libx264 @ 0x25020c0] frame I:1     Avg QP:22.96  size: 26404\n",
      "[libx264 @ 0x25020c0] mb I  I16..4: 30.7% 69.1%  0.2%\n",
      "[libx264 @ 0x25020c0] 8x8 transform intra:69.1%\n",
      "[libx264 @ 0x25020c0] coded y,uvDC,uvAC intra: 26.0% 55.6% 5.2%\n",
      "[libx264 @ 0x25020c0] i16 v,h,dc,p: 18% 24%  5% 53%\n",
      "[libx264 @ 0x25020c0] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 42% 21% 13%  5%  4%  4%  4%  4%  3%\n",
      "[libx264 @ 0x25020c0] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 50% 15% 10%  5%  5%  5%  4%  6%  1%\n",
      "[libx264 @ 0x25020c0] i8c dc,h,v,p: 45% 18% 28%  8%\n",
      "[libx264 @ 0x25020c0] kb/s:5069.57\n",
      "ffmpeg version 4.0.2 Copyright (c) 2000-2018 the FFmpeg developers\n",
      "  built with gcc 4.8.2 (GCC) 20140120 (Red Hat 4.8.2-15)\n",
      "  configuration: --prefix=/home/conda/feedstock_root/build_artifacts/ffmpeg_1539667330082/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --disable-doc --disable-openssl --enable-shared --enable-static --extra-cflags='-Wall -g -m64 -pipe -O3 -march=x86-64 -fPIC' --extra-cxxflags='-Wall -g -m64 -pipe -O3 -march=x86-64 -fPIC' --extra-libs='-lpthread -lm -lz' --enable-zlib --enable-pic --enable-pthreads --enable-gpl --enable-version3 --enable-hardcoded-tables --enable-avresample --enable-libfreetype --enable-gnutls --enable-libx264 --enable-libopenh264\n",
      "  libavutil      56. 14.100 / 56. 14.100\n",
      "  libavcodec     58. 18.100 / 58. 18.100\n",
      "  libavformat    58. 12.100 / 58. 12.100\n",
      "  libavdevice    58.  3.100 / 58.  3.100\n",
      "  libavfilter     7. 16.100 /  7. 16.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  1.100 /  5.  1.100\n",
      "  libswresample   3.  1.100 /  3.  1.100\n",
      "  libpostproc    55.  1.100 / 55.  1.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/home/bean/DragVideo/Data_store/OLD/original_videos/gadot_tanned_left.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.12.100\n",
      "  Duration: 00:00:08.20, start: 0.000000, bitrate: 1434 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1024x1024, 1430 kb/s, 30 fps, 30 tbr, 15360 tbn, 60 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Input #1, mov,mp4,m4a,3gp,3g2,mj2, from '/home/bean/DragVideo/Data_store/experiments/2023-09-06_00-38-36_actress_smile/videos/post_drag_full.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.12.100\n",
      "  Duration: 00:00:00.04, start: 0.000000, bitrate: 2833 kb/s\n",
      "    Stream #1:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1024x1024, 2703 kb/s, 24 fps, 24 tbr, 12288 tbn, 48 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> hstack:input0\n",
      "  Stream #1:0 (h264) -> hstack:input1\n",
      "  hstack -> Stream #0:0 (libx264)\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x76db00] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x76db00] profile High, level 4.0\n",
      "[libx264 @ 0x76db00] 264 - core 152 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=18 lookahead_threads=3 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to '/home/bean/DragVideo/Data_store/experiments/2023-09-06_00-38-36_actress_smile/videos/hstack_original_post_drag_full.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.12.100\n",
      "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 2048x1024, q=-1--1, 30 fps, 15360 tbn, 30 tbc (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.18.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=    1 fps=0.0 q=29.0 Lsize=      26kB time=00:00:00.00 bitrate=3323815.4kbits/s speed=0.000958x    \n",
      "video:26kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 3.052736%\n",
      "[libx264 @ 0x76db00] frame I:1     Avg QP:23.72  size: 25530\n",
      "[libx264 @ 0x76db00] mb I  I16..4: 28.5% 71.1%  0.4%\n",
      "[libx264 @ 0x76db00] 8x8 transform intra:71.1%\n",
      "[libx264 @ 0x76db00] coded y,uvDC,uvAC intra: 23.5% 53.4% 5.7%\n",
      "[libx264 @ 0x76db00] i16 v,h,dc,p: 22% 25%  6% 47%\n",
      "[libx264 @ 0x76db00] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 46% 19% 12%  4%  4%  4%  4%  4%  3%\n",
      "[libx264 @ 0x76db00] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 45% 15% 10%  6%  7%  7%  5%  5%  2%\n",
      "[libx264 @ 0x76db00] i8c dc,h,v,p: 46% 18% 28%  7%\n",
      "[libx264 @ 0x76db00] kb/s:6127.20\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# hstack videos\n",
    "# =============================================================================\n",
    "\n",
    "video1= os.path.join(videos_dir,\"pre_drag_full.mp4\")\n",
    "video2= os.path.join(videos_dir,\"post_drag_full.mp4\")\n",
    "\n",
    "# pre_post_drag_full\n",
    "ffmpeg_utils.ffmpeg.hstack_videos(video1,\n",
    "                                  video2,\n",
    "                                  output_dir=videos_dir,\n",
    "                                  output_name=\"hstack_pre_post_drag_full\",\n",
    ")\n",
    "\n",
    "# original_post_drag_full\n",
    "ffmpeg_utils.ffmpeg.hstack_videos(lazy_config['video_path'],\n",
    "                                  video2,\n",
    "                                  output_dir=videos_dir,\n",
    "                                  output_name=\"hstack_original_post_drag_full\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stylegan3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
