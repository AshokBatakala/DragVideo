{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def align_faces_2(root_path):\n",
    "    import os \n",
    "    current_path = os.getcwd()\n",
    "    temp_path = \"/home/bean/DragVideo/stylegan3-editing\"\n",
    "    os.chdir(temp_path)\n",
    "    command =f\"\"\"python prepare_data/preparing_faces_parallel.py \\\n",
    "                --mode align \\\n",
    "                --root_path  {root_path} \n",
    "                \"\"\"\n",
    "    import subprocess\n",
    "    subprocess.run(command, shell=True)\n",
    "    os.chdir(current_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DRAGVIDEO_ROOT_PATH = \"/Ext_4T_SSD/ASHOK/\"\n",
    "DRAGVIDEO_ROOT_PATH = \"/home/bean/\"\n",
    "\n",
    "# keep matching encoder,SG as pairt \n",
    "old = {\"encoder\":  f\"{DRAGVIDEO_ROOT_PATH}DragVideo/DragGAN/_PTI/pretrained_models/e4e_ffhq_encode.pt\",\n",
    "       \"SG\": f\"{DRAGVIDEO_ROOT_PATH}DragVideo/DragGAN/_PTI/pretrained_models/ffhq.pkl\",\n",
    "       \"model_name\":\"stylegan2\",\n",
    "       \"resolution\":1024,\n",
    "       }\n",
    "\n",
    "new = {\"encoder\": f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/OLD/model_weights/restyle_e4e_ffhq.pt\",\n",
    "         \"SG\":  f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/OLD/model_weights/stylegan3_3rdtime_weights/stylegan3-r-ffhq-1024_module.pkl\",\n",
    "         \"model_name\":\"stylegan3\",\n",
    "               \"resolution\":1024,\n",
    "         }\n",
    "\n",
    "new_256 = {\"encoder\": f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/OLD/model_weights/restyle_e4e_ffhq.pt\",\n",
    "         \"SG\":  f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/OLD/Stylegan3_1_files/stylegan3-r-ffhqu-256x256.pkl\",\n",
    "         \"model_name\":\"stylegan3\",\n",
    "         \"resolution\":256,\n",
    "         }\n",
    "\n",
    "videos = {\n",
    "       \"obama\": f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/OLD/original_videos/obama.mp4\",\n",
    "       \"man_speaking\": f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/OLD/original_videos/person_speaking_original.mp4\",\n",
    "       \"rahul\": f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/OLD/original_videos/rahul.mp4\",\n",
    "       \"alien_girl\": f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/OLD/original_videos/alien_girl.mp4\",\n",
    "       \"mirrAR\": f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/OLD/original_videos/mirrAR.mp4\",\n",
    "       \"vsauce_frnd\":f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/OLD/original_videos/micheal_friendzone.mp4\",\n",
    "       \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME_POSTFIX = \"vsauce_ffmpeg\"#\"aligned_sg3_&_new_e4e_reconstruction_invstep_200_pti_step_450\"\n",
    "models_set = new\n",
    "Testing =True\n",
    "# --------------------------------  \n",
    "\n",
    "\n",
    "import datetime\n",
    "lazy_config = {\n",
    "    \"EXP_NAME\": str(datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))+\"_\"+ EXPERIMENT_NAME_POSTFIX,\n",
    "    # \"EXP_NAME\": \"/home/bean/DragVideo/Data_store/experiments/_SAVE_mirrAR_200_frames_2\",\n",
    "    \"e4e\": models_set['encoder'],\n",
    "    \"stylegan2_ada_ffhq\": models_set['SG'],\n",
    "    \"video_path\":  videos[\"vsauce_frnd\"],\n",
    "    \"model_name\" : models_set['model_name'],\n",
    "    \"n_frames\" : 1,#120,#200,\n",
    "    \"IMAGE_SIZE\": models_set[\"resolution\"],\n",
    "    \"N_STEPS_in_draggan\":  \"150\",\n",
    "    \"editing_function_name\":\"large_eyes\",#\"large_eyes\" # \"make_jaw_wider\" # \"mouth_wide\"\n",
    "    \"fps\": 24,\n",
    "    \n",
    "}\n",
    "\n",
    "env_config = {\n",
    "    \"DragGAN_dir\": f\"{DRAGVIDEO_ROOT_PATH}DragVideo/DragGAN\",\n",
    "    \"Experiment_base_path\":f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/experiments/\" ,\n",
    "    \"init_exp_dir_shell_path\": f\"{DRAGVIDEO_ROOT_PATH}DragVideo/DragGAN/_PTI/init_datadirs.sh\",\n",
    "    \"dummy_config_path\" : f\"{DRAGVIDEO_ROOT_PATH}DragVideo/DragGAN/_PTI/configs/dummy\",\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "#hyper parameters in PTI\n",
    "\n",
    "hyper_config = {\n",
    "    \"max_pti_steps\": 350,\n",
    "    \"first_inv_steps\":450,\n",
    "    \"max_images_to_invert\": 200,\n",
    "}\n",
    "\n",
    "if Testing: \n",
    "    hyper_config[\"max_pti_steps\"] = 1\n",
    "    hyper_config[\"first_inv_steps\"] = 1\n",
    "    hyper_config[\"max_images_to_invert\"] = 5\n",
    "    lazy_config[\"N_STEPS_in_draggan\"] = '1'\n",
    "    \n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------\n",
    "\n",
    "from run_utils import *\n",
    "\n",
    "# create experiment data folder structure\n",
    "Experiment_name = lazy_config[\"EXP_NAME\"]\n",
    "Experiment_base_path = env_config[\"Experiment_base_path\"]\n",
    "Experiment_path = os.path.join(Experiment_base_path, Experiment_name)\n",
    "\n",
    "init_experiment_dir(Experiment_name,Experiment_base_path,shell_script_path=env_config[\"init_exp_dir_shell_path\"])\n",
    "\n",
    "\n",
    "\n",
    "# dummy paths_config overwrites the paths_config.py\n",
    "# dummy_config_path = f\"{DRAGVIDEO_ROOT_PATH}DragVideo/DragGAN/_PTI/configs/dummy'\n",
    "add_dummy_config_from_dict(\"hyperparameters.py\", hyper_config,ROOT_PATH=env_config[\"dummy_config_path\"])\n",
    "\n",
    "# change path configs , hyperparameters \n",
    "paths_config_dict = {\n",
    "    #pretrained models\n",
    "    \"e4e\": lazy_config[\"e4e\"],\n",
    "    \"stylegan2_ada_ffhq\": lazy_config[\"stylegan2_ada_ffhq\"],\n",
    "    \n",
    "    # to store tuned stylegan weights\n",
    "    \"checkpoints_dir\": os.path.join(Experiment_path,'tuned_SG'),\n",
    "    # to store latents\n",
    "    \"embedding_base_dir\": os.path.join(Experiment_path,'latents'),\n",
    "    # aligned / processed images\n",
    "    \"input_data_path\": os.path.join(Experiment_path,'aligned'),\n",
    "     \"quad_values_path\": os.path.join(Experiment_path,'quad_values'),\n",
    "}\n",
    "\n",
    "add_dummy_config_from_dict(\"paths_config.py\", paths_config_dict,ROOT_PATH=env_config[\"dummy_config_path\"])\n",
    "\n",
    "\n",
    "\n",
    "# add all these configs to log.txt\n",
    "# --------------------------------  \n",
    "with open(os.path.join(Experiment_path,'log.txt'), 'a') as f:\n",
    "    import json\n",
    "    f.write(f\"lazy_config: {json.dumps(lazy_config, indent=4)}\\n\")\n",
    "    f.write(f\"env_config: {json.dumps(env_config, indent=4)}\\n\")\n",
    "    f.write(f\"hyper_config: {json.dumps(hyper_config, indent=4)}\\n\")\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.0.2 Copyright (c) 2000-2018 the FFmpeg developers\n",
      "  built with gcc 4.8.2 (GCC) 20140120 (Red Hat 4.8.2-15)\n",
      "  configuration: --prefix=/home/conda/feedstock_root/build_artifacts/ffmpeg_1539667330082/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --disable-doc --disable-openssl --enable-shared --enable-static --extra-cflags='-Wall -g -m64 -pipe -O3 -march=x86-64 -fPIC' --extra-cxxflags='-Wall -g -m64 -pipe -O3 -march=x86-64 -fPIC' --extra-libs='-lpthread -lm -lz' --enable-zlib --enable-pic --enable-pthreads --enable-gpl --enable-version3 --enable-hardcoded-tables --enable-avresample --enable-libfreetype --enable-gnutls --enable-libx264 --enable-libopenh264\n",
      "  libavutil      56. 14.100 / 56. 14.100\n",
      "  libavcodec     58. 18.100 / 58. 18.100\n",
      "  libavformat    58. 12.100 / 58. 12.100\n",
      "  libavdevice    58.  3.100 / 58.  3.100\n",
      "  libavfilter     7. 16.100 /  7. 16.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  1.100 /  5.  1.100\n",
      "  libswresample   3.  1.100 /  3.  1.100\n",
      "  libpostproc    55.  1.100 / 55.  1.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/home/bean/DragVideo/Data_store/OLD/original_videos/micheal_friendzone.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Duration: 00:00:13.08, start: 0.000000, bitrate: 1882 kb/s\n",
      "    Stream #0:0(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 134 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "    Stream #0:1(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, unknown/bt709/bt709), 1280x720 [SAR 1:1 DAR 16:9], 1740 kb/s, 25 fps, 25 tbr, 12800 tbn, 50 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      encoder         : Lavc59.37.100 libx264\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (h264 (native) -> png (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, image2, to '/home/bean/DragVideo/Data_store/experiments/2023-08-25_21-36-33_vsauce_ffmpeg/raw/%03d.png':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.12.100\n",
      "    Stream #0:0(und): Video: png, rgb24, 1280x720 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 24 fps, 24 tbn, 24 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      encoder         : Lavc58.18.100 png\n",
      "frame=    1 fps=0.0 q=-0.0 Lsize=N/A time=00:00:00.04 bitrate=N/A speed=0.684x    \n",
      "video:378kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n"
     ]
    }
   ],
   "source": [
    "# extract frames from video\n",
    "#==============================================================================\n",
    "\n",
    "from importlib.machinery import SourceFileLoader\n",
    "# imports the module from the given path\n",
    "# video_utils = SourceFileLoader(\"video_utils\",\"../utils_draggan/video_utils.py\").load_module()\n",
    "\n",
    "ffmpeg_utils = SourceFileLoader(\"video_utils\",\"../utils_draggan/ffmpeg_utils.py\").load_module()\n",
    "raw_path = os.path.join(Experiment_path, \"raw\")\n",
    "\n",
    "# video_utils.extract_frames(lazy_config['video_path'], raw_path,n_frames=lazy_config['n_frames'])\n",
    "ffmpeg_utils.ffmpeg.extract_frames(video_path = lazy_config['video_path'],\n",
    "                                      output_frames_dir = raw_path,\n",
    "                                      fps = lazy_config['fps'],\n",
    "                                      first_n_frames = lazy_config['n_frames'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.align_data import pre_process_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # delete this cell \n",
    "# # \"/home/bean/DragVideo/Data_store/man_speaking/aligned\": input_data_path \n",
    "# # \"/home/bean/DragVideo/Data_store/man_speaking/quad_values\", quad_pkl_path\n",
    "\n",
    "# raw_path = \"/home/bean/DragVideo/Data_store/man_speaking/raw\"\n",
    "# pre_process_images(raw_path, IMAGE_SIZE=1024) # o/p: config.input_data_path ,quad pickle dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving aligned images...\n",
      "saving quad values...\n",
      "done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.align_data import pre_process_images\n",
    "pre_process_images(raw_path, IMAGE_SIZE=lazy_config['IMAGE_SIZE']) # o/p: config.input_data_path ,quad pickle dir\n",
    "#\n",
    "# align_faces_2(os.path.join(Experiment_path,'raw'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bean/.conda/envs/stylegan3/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/bean/.conda/envs/stylegan3/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bean/.conda/envs/stylegan3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/bean/.conda/envs/stylegan3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/bean/.conda/envs/stylegan3/lib/python3.9/site-packages/lpips/weights/v0.1/alex.pth\n",
      "current_directory:  /home/bean/DragVideo/DragGAN/_PTI\n",
      "current_directory:  /home/bean/DragVideo/DragGAN/_PTI\n",
      "torch.Size([3, 1024, 1024]) 3 1024 1024\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bean/.conda/envs/stylegan3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501: UserWarning: operator() profile_node %106 : int = prim::profile_ivalue(%104)\n",
      " does not have profile information (Triggered internally at /opt/conda/conda-bld/pytorch_1682343964576/work/third_party/nvfuser/csrc/graph_fuser.cpp:104.)\n",
      "  return forward_call(*args, **kwargs)\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.38s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting large updated pickle based off new generator and ffhq.pkl\n",
      "pwd /home/bean/DragVideo/DragGAN/_facial-landmarks-recognition\n",
      "landmark_path:  /home/bean/DragVideo/Data_store/experiments/2023-08-25_21-36-33_vsauce_ffmpeg/landmarks/000.pkl\n"
     ]
    }
   ],
   "source": [
    "from utils.align_data import pre_process_images\n",
    "from scripts.run_pti import run_PTI\n",
    "\n",
    "from run_utils_2 import load_generators,export_updated_pickle\n",
    "from configs import paths_config\n",
    "\n",
    "use_multi_id_training = True\n",
    "model_id = run_PTI(use_wandb=False, use_multi_id_training=use_multi_id_training)\n",
    "\n",
    "generator_type =paths_config.multi_id_model_type if use_multi_id_training else \"__\"\n",
    "old_G, new_G = load_generators(model_id, generator_type)\n",
    "sg_tuned_pkl = export_updated_pickle(new_G,model_id,name = lazy_config[\"model_name\"])\n",
    "\n",
    "# print(sg_tuned_pkl) # 'QBUXQCXZGWET'\n",
    "\n",
    "\n",
    "\n",
    "#get landmarks\n",
    "landmark_path = f\"{DRAGVIDEO_ROOT_PATH}DragVideo/DragGAN/_facial-landmarks-recognition\"\n",
    "os.chdir(landmark_path)\n",
    "print(\"pwd\",os.getcwd())\n",
    "import sys\n",
    "sys.path.append(landmark_path)\n",
    "\n",
    "from main import landmarks, dict_landmarks,show_landmarks,get_landmarks_dir\n",
    "\n",
    "# to store landmarks\n",
    "landmarks_dir =  os.path.join(Experiment_path,'landmarks')\n",
    "processed_images_dir =  os.path.join(Experiment_path,'aligned')\n",
    "\n",
    "# generate landmarks for all images in processed_images_dir\n",
    "get_landmarks_dir(processed_images_dir,landmarks_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runs draggan part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# just to run this part seperately\n",
    "import os \n",
    "# Experiment_path = \"/home/bean/DragVideo/Data_store/experiments/_SAVE_vsauce_ffmpeg_large_eyes_dr_160\"\n",
    "# sg_tuned_pkl = \"/home/bean/DragVideo/Data_store/experiments/_SAVE_vsauce_ffmpeg_large_eyes_dr_160/tuned_SG/stylegan3_EZXZEVVUYSPX.pkl\"\n",
    "\n",
    "# Experiment_path =  f\"/home/bean/DragVideo/Data_store/experiments/{lazy_config['EXP_NAME']}\"\t\n",
    "sg_tuned_pkl = new[\"SG\"]\n",
    "\n",
    "\n",
    "lazy_config[\"N_STEPS_in_draggan\"]=\"160\"\n",
    "lazy_config[\"editing_function_name\"]=\"large_eyes\"\n",
    "lazy_config[\"IMAGE_SIZE\"]=\"1024\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sg_tuned_pkl: /home/bean/DragVideo/Data_store/OLD/model_weights/stylegan3_3rdtime_weights/stylegan3-r-ffhq-1024_module.pkl\n",
      "editing_function_name: large_eyes\n",
      "intiating global state....\n",
      "calling init_images......\n",
      "Loading \"/home/bean/DragVideo/Data_store/OLD/model_weights/stylegan3_3rdtime_weights/stylegan3-r-ffhq-1024_module.pkl\"... Done.\n",
      "()\n",
      "{'z_dim': 512, 'w_dim': 512, 'channel_base': 65536, 'channel_max': 1024, 'mapping_kwargs': {}, 'conv_kernel': 1, 'filter_size': 6, 'magnitude_ema_beta': 0.9988915792636801, 'output_scale': 0.25, 'c_dim': 0, 'img_resolution': 1024, 'img_channels': 3, 'use_radial_filters': True}\n",
      "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/160 [00:00<?, ?it/s]/home/bean/.conda/envs/stylegan3/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343964576/work/aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      " 51%|█████▏    | 82/160 [01:03<00:59,  1.30it/s]"
     ]
    }
   ],
   "source": [
    "# clean all data from gpu\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "os.chdir(env_config[\"DragGAN_dir\"])\n",
    "import subprocess\n",
    "\n",
    "print(f\"sg_tuned_pkl: {sg_tuned_pkl}\")\n",
    "\n",
    "subprocess.call(['python', '_run_dragvideo.py',\n",
    "                 '--Experiment_path', Experiment_path,\n",
    "                 '--N_STEPS',       lazy_config[\"N_STEPS_in_draggan\"],\n",
    "                 '--CHECKPOINT_PATH', sg_tuned_pkl,\n",
    "                 \"--MAX_SIZE\",      str(lazy_config[\"IMAGE_SIZE\"]),\n",
    "                 \"--editing_function_name\",lazy_config[\"editing_function_name\"],\n",
    "])\n",
    "                #  \"--verbose\",       \"False\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/bean/DragVideo/DragGAN'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "os.getcwd()\n",
    "# import importlib\n",
    "# importlib.reload(ffmpeg_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utils import de_alignment \n",
    "put_back_the_edited_image = de_alignment.put_back_the_edited_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def paste_edited_faces_back(dir_path,edited_dir='after_drag',save_dir='edit_pasted'):\n",
    "    raw_dir = os.path.join(dir_path,'raw')\n",
    "    edited_dir = os.path.join(dir_path,edited_dir)\n",
    "    quad_dir = os.path.join(dir_path,'quad_values')\n",
    "    save_dir = os.path.join(dir_path,save_dir)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # get names from edited_dir\n",
    "    names = [name.split('.')[0] for name in os.listdir(edited_dir)]\n",
    "    for name in tqdm(names):\n",
    "        raw_image = os.path.join(raw_dir,name+'.png')\n",
    "        edited_image = os.path.join(edited_dir,name+'.png')\n",
    "        quad_path = os.path.join(quad_dir,name+'.pkl')\n",
    "        save_path = os.path.join(save_dir,name+'.png')\n",
    "        put_back_the_edited_image(raw_image,edited_image,quad_path,save_path=save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "paste_edited_faces_back(Experiment_path,edited_dir=\"before_drag\",save_dir=\"before_drag_pasted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# dir_path = \"/home/bean/DragVideo/Data_store/man_speaking\"\n",
    "paste_edited_faces_back(Experiment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.0.2 Copyright (c) 2000-2018 the FFmpeg developers\n",
      "  built with gcc 4.8.2 (GCC) 20140120 (Red Hat 4.8.2-15)\n",
      "  configuration: --prefix=/home/conda/feedstock_root/build_artifacts/ffmpeg_1539667330082/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --disable-doc --disable-openssl --enable-shared --enable-static --extra-cflags='-Wall -g -m64 -pipe -O3 -march=x86-64 -fPIC' --extra-cxxflags='-Wall -g -m64 -pipe -O3 -march=x86-64 -fPIC' --extra-libs='-lpthread -lm -lz' --enable-zlib --enable-pic --enable-pthreads --enable-gpl --enable-version3 --enable-hardcoded-tables --enable-avresample --enable-libfreetype --enable-gnutls --enable-libx264 --enable-libopenh264\n",
      "  libavutil      56. 14.100 / 56. 14.100\n",
      "  libavcodec     58. 18.100 / 58. 18.100\n",
      "  libavformat    58. 12.100 / 58. 12.100\n",
      "  libavdevice    58.  3.100 / 58.  3.100\n",
      "  libavfilter     7. 16.100 /  7. 16.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  1.100 /  5.  1.100\n",
      "  libswresample   3.  1.100 /  3.  1.100\n",
      "  libpostproc    55.  1.100 / 55.  1.100\n",
      "[image2 @ 0x1b3c340] Could not open file : ./*.png\n",
      "[image2 @ 0x1b3c340] Could not find codec parameters for stream 0 (Video: png, none(pc)): unspecified size\n",
      "Consider increasing the value for the 'analyzeduration' and 'probesize' options\n",
      "Input #0, image2, from './*.png':\n",
      "  Duration: 00:00:00.04, start: 0.000000, bitrate: N/A\n",
      "    Stream #0:0: Video: png, none(pc), 24 tbr, 24 tbn, 24 tbc\n",
      "Output #0, mp4, to '/home/bean/DragVideo/Data_store/experiments/2023-08-25_21-36-33_vsauce_ffmpeg/videos/pre_drag_full.mp4':\n",
      "Output file #0 does not contain any stream\n",
      "ffmpeg version 4.0.2 Copyright (c) 2000-2018 the FFmpeg developers\n",
      "  built with gcc 4.8.2 (GCC) 20140120 (Red Hat 4.8.2-15)\n",
      "  configuration: --prefix=/home/conda/feedstock_root/build_artifacts/ffmpeg_1539667330082/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --disable-doc --disable-openssl --enable-shared --enable-static --extra-cflags='-Wall -g -m64 -pipe -O3 -march=x86-64 -fPIC' --extra-cxxflags='-Wall -g -m64 -pipe -O3 -march=x86-64 -fPIC' --extra-libs='-lpthread -lm -lz' --enable-zlib --enable-pic --enable-pthreads --enable-gpl --enable-version3 --enable-hardcoded-tables --enable-avresample --enable-libfreetype --enable-gnutls --enable-libx264 --enable-libopenh264\n",
      "  libavutil      56. 14.100 / 56. 14.100\n",
      "  libavcodec     58. 18.100 / 58. 18.100\n",
      "  libavformat    58. 12.100 / 58. 12.100\n",
      "  libavdevice    58.  3.100 / 58.  3.100\n",
      "  libavfilter     7. 16.100 /  7. 16.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  1.100 /  5.  1.100\n",
      "  libswresample   3.  1.100 /  3.  1.100\n",
      "  libpostproc    55.  1.100 / 55.  1.100\n",
      "[image2 @ 0x1ab0340] Could not open file : ./*.png\n",
      "[image2 @ 0x1ab0340] Could not find codec parameters for stream 0 (Video: png, none(pc)): unspecified size\n",
      "Consider increasing the value for the 'analyzeduration' and 'probesize' options\n",
      "Input #0, image2, from './*.png':\n",
      "  Duration: 00:00:00.04, start: 0.000000, bitrate: N/A\n",
      "    Stream #0:0: Video: png, none(pc), 24 tbr, 24 tbn, 24 tbc\n",
      "Output #0, mp4, to '/home/bean/DragVideo/Data_store/experiments/2023-08-25_21-36-33_vsauce_ffmpeg/videos/post_drag_full.mp4':\n",
      "Output file #0 does not contain any stream\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# using ffmpeg to make video\n",
    "# =============================================================================\n",
    "before_drag_pasted_dir = os.path.join(Experiment_path,'before_drag_pasted')\n",
    "after_drag_pasted_dir = os.path.join(Experiment_path,'edit_pasted')\n",
    "videos_dir = os.path.join(Experiment_path,'videos')\n",
    "\n",
    "ffmpeg_utils.ffmpeg.make_video(before_drag_pasted_dir,\n",
    "                               video_name=\"pre_drag_full\",\n",
    "                               video_dir=videos_dir,\n",
    "                               fps=lazy_config['fps'],\n",
    "                                 )\n",
    "ffmpeg_utils.ffmpeg.make_video(after_drag_pasted_dir,\n",
    "                                 video_name=\"post_drag_full\",\n",
    "                                    video_dir=videos_dir,\n",
    "                                    fps=lazy_config['fps'],\n",
    "                                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.0.2 Copyright (c) 2000-2018 the FFmpeg developers\n",
      "  built with gcc 4.8.2 (GCC) 20140120 (Red Hat 4.8.2-15)\n",
      "  configuration: --prefix=/home/conda/feedstock_root/build_artifacts/ffmpeg_1539667330082/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --disable-doc --disable-openssl --enable-shared --enable-static --extra-cflags='-Wall -g -m64 -pipe -O3 -march=x86-64 -fPIC' --extra-cxxflags='-Wall -g -m64 -pipe -O3 -march=x86-64 -fPIC' --extra-libs='-lpthread -lm -lz' --enable-zlib --enable-pic --enable-pthreads --enable-gpl --enable-version3 --enable-hardcoded-tables --enable-avresample --enable-libfreetype --enable-gnutls --enable-libx264 --enable-libopenh264\n",
      "  libavutil      56. 14.100 / 56. 14.100\n",
      "  libavcodec     58. 18.100 / 58. 18.100\n",
      "  libavformat    58. 12.100 / 58. 12.100\n",
      "  libavdevice    58.  3.100 / 58.  3.100\n",
      "  libavfilter     7. 16.100 /  7. 16.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  1.100 /  5.  1.100\n",
      "  libswresample   3.  1.100 /  3.  1.100\n",
      "  libpostproc    55.  1.100 / 55.  1.100\n",
      "/home/bean/DragVideo/Data_store/experiments/2023-08-25_21-36-33_vsauce_ffmpeg/videos/pre_drag_full.mp4: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bean/DragVideo/Data_store/experiments/2023-08-25_21-36-33_vsauce_ffmpeg/videos/hstack_pre_post_drag_full.mp4\n",
      "/home/bean/DragVideo/Data_store/experiments/2023-08-25_21-36-33_vsauce_ffmpeg/videos/hstack_original_post_drag_full.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.0.2 Copyright (c) 2000-2018 the FFmpeg developers\n",
      "  built with gcc 4.8.2 (GCC) 20140120 (Red Hat 4.8.2-15)\n",
      "  configuration: --prefix=/home/conda/feedstock_root/build_artifacts/ffmpeg_1539667330082/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --disable-doc --disable-openssl --enable-shared --enable-static --extra-cflags='-Wall -g -m64 -pipe -O3 -march=x86-64 -fPIC' --extra-cxxflags='-Wall -g -m64 -pipe -O3 -march=x86-64 -fPIC' --extra-libs='-lpthread -lm -lz' --enable-zlib --enable-pic --enable-pthreads --enable-gpl --enable-version3 --enable-hardcoded-tables --enable-avresample --enable-libfreetype --enable-gnutls --enable-libx264 --enable-libopenh264\n",
      "  libavutil      56. 14.100 / 56. 14.100\n",
      "  libavcodec     58. 18.100 / 58. 18.100\n",
      "  libavformat    58. 12.100 / 58. 12.100\n",
      "  libavdevice    58.  3.100 / 58.  3.100\n",
      "  libavfilter     7. 16.100 /  7. 16.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  1.100 /  5.  1.100\n",
      "  libswresample   3.  1.100 /  3.  1.100\n",
      "  libpostproc    55.  1.100 / 55.  1.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/home/bean/DragVideo/Data_store/OLD/original_videos/micheal_friendzone.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Duration: 00:00:13.08, start: 0.000000, bitrate: 1882 kb/s\n",
      "    Stream #0:0(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 134 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "    Stream #0:1(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, unknown/bt709/bt709), 1280x720 [SAR 1:1 DAR 16:9], 1740 kb/s, 25 fps, 25 tbr, 12800 tbn, 50 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      encoder         : Lavc59.37.100 libx264\n",
      "/home/bean/DragVideo/Data_store/experiments/2023-08-25_21-36-33_vsauce_ffmpeg/videos/post_drag_full.mp4: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# hstack videos\n",
    "# =============================================================================\n",
    "\n",
    "video1= os.path.join(videos_dir,\"pre_drag_full.mp4\")\n",
    "video2= os.path.join(videos_dir,\"post_drag_full.mp4\")\n",
    "\n",
    "# pre_post_drag_full\n",
    "ffmpeg_utils.ffmpeg.hstack_videos(video1,\n",
    "                                  video2,\n",
    "                                  output_dir=videos_dir,\n",
    "                                  output_name=\"hstack_pre_post_drag_full\",\n",
    ")\n",
    "\n",
    "# original_post_drag_full\n",
    "ffmpeg_utils.ffmpeg.hstack_videos(lazy_config['video_path'],\n",
    "                                  video2,\n",
    "                                  output_dir=videos_dir,\n",
    "                                  output_name=\"hstack_original_post_drag_full\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stylegan3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
