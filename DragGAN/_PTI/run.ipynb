{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to run it \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/danielroich/PTI\n",
    "\n",
    "# run below commands from /PTI/ \n",
    "# export PYTHONPATH=$PYTHONPATH:$PWD\n",
    "\n",
    "# change path inside it.\n",
    "# python utils/align_data.py\n",
    "\n",
    "# path_ = \"/home/bean/DragVideo/PTI\"\n",
    "# import os \n",
    "# os.chdir(path_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os \n",
    "# dir = \"/workspace/PTI/data/raw_images\"\n",
    "# # it has images from 0 to 400 .jpeg \n",
    "# # rename them so that all are 3 digits\n",
    "# for i in range(400):\n",
    "#     if i < 10:\n",
    "#         os.rename(dir + \"/\" + str(i) + \".jpg\", dir + \"/00\" + str(i) + \".jpg\")\n",
    "#     elif i < 100:\n",
    "#         os.rename(dir + \"/\" + str(i) + \".jpg\", dir + \"/0\" + str(i) + \".jpg\")\n",
    "#     else:\n",
    "#         continue\n",
    "#         # os.rename(dir + \"/\" + str(i) + \".jpeg\", dir + \"/\" + str(i) + \".jpeg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bean/.conda/envs/stylegan3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/bean/.conda/envs/stylegan3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/bean/.conda/envs/stylegan3/lib/python3.9/site-packages/lpips/weights/v0.1/alex.pth\n",
      "current_directory:  /home/bean/DragVideo/PTI\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m use_multi_id_training \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscripts\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrun_pti\u001b[39;00m \u001b[39mimport\u001b[39;00m run_PTI\n\u001b[0;32m----> 9\u001b[0m model_id \u001b[39m=\u001b[39m run_PTI(use_wandb\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, use_multi_id_training\u001b[39m=\u001b[39;49muse_multi_id_training)\n",
      "File \u001b[0;32m~/DragVideo/PTI/scripts/run_pti.py:38\u001b[0m, in \u001b[0;36mrun_PTI\u001b[0;34m(run_name, use_wandb, use_multi_id_training)\u001b[0m\n\u001b[1;32m     35\u001b[0m dataloader \u001b[39m=\u001b[39m DataLoader(dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     37\u001b[0m \u001b[39mif\u001b[39;00m use_multi_id_training:\n\u001b[0;32m---> 38\u001b[0m     coach \u001b[39m=\u001b[39m MultiIDCoach(dataloader, use_wandb)\n\u001b[1;32m     39\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m     coach \u001b[39m=\u001b[39m SingleIDCoach(dataloader, use_wandb)\n",
      "File \u001b[0;32m~/DragVideo/PTI/training/coaches/multi_id_coach.py:14\u001b[0m, in \u001b[0;36mMultiIDCoach.__init__\u001b[0;34m(self, data_loader, use_wandb)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, data_loader, use_wandb):\n\u001b[0;32m---> 14\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(data_loader, use_wandb)\n",
      "File \u001b[0;32m~/DragVideo/PTI/training/coaches/base_coach.py:39\u001b[0m, in \u001b[0;36mBaseCoach.__init__\u001b[0;34m(self, data_loader, use_wandb)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39m# Initialize loss\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlpips_loss \u001b[39m=\u001b[39m LPIPS(net\u001b[39m=\u001b[39mhyperparameters\u001b[39m.\u001b[39mlpips_type)\u001b[39m.\u001b[39mto(global_config\u001b[39m.\u001b[39mdevice)\u001b[39m.\u001b[39meval()\n\u001b[0;32m---> 39\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrestart_training()\n\u001b[1;32m     41\u001b[0m \u001b[39m# Initialize checkpoint dir\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheckpoint_dir \u001b[39m=\u001b[39m paths_config\u001b[39m.\u001b[39mcheckpoints_dir\n",
      "File \u001b[0;32m~/DragVideo/PTI/training/coaches/base_coach.py:48\u001b[0m, in \u001b[0;36mBaseCoach.restart_training\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrestart_training\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     46\u001b[0m \n\u001b[1;32m     47\u001b[0m     \u001b[39m# Initialize networks\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mG \u001b[39m=\u001b[39m load_old_G()\n\u001b[1;32m     49\u001b[0m     toogle_grad(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mG, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     51\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moriginal_G \u001b[39m=\u001b[39m load_old_G()\n",
      "File \u001b[0;32m~/DragVideo/PTI/utils/models_utils.py:26\u001b[0m, in \u001b[0;36mload_old_G\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mcurrent_directory: \u001b[39m\u001b[39m'\u001b[39m,os\u001b[39m.\u001b[39mgetcwd())\n\u001b[1;32m     25\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(paths_config\u001b[39m.\u001b[39mstylegan2_ada_ffhq, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m---> 26\u001b[0m     old_G \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(f)[\u001b[39m'\u001b[39m\u001b[39mG_ema\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(global_config\u001b[39m.\u001b[39mdevice)\u001b[39m.\u001b[39meval()\n\u001b[1;32m     27\u001b[0m     old_G \u001b[39m=\u001b[39m old_G\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m     28\u001b[0m \u001b[39mreturn\u001b[39;00m old_G\n",
      "File \u001b[0;32m~/DragVideo/PTI/torch_utils/persistence.py:191\u001b[0m, in \u001b[0;36m_reconstruct_persistent_obj\u001b[0;34m(meta)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[39massert\u001b[39;00m meta \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[39massert\u001b[39;00m meta\u001b[39m.\u001b[39mversion \u001b[39m==\u001b[39m _version\n\u001b[0;32m--> 191\u001b[0m module \u001b[39m=\u001b[39m _src_to_module(meta\u001b[39m.\u001b[39;49mmodule_src)\n\u001b[1;32m    193\u001b[0m \u001b[39massert\u001b[39;00m meta\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    194\u001b[0m orig_class \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[meta\u001b[39m.\u001b[39mclass_name]\n",
      "File \u001b[0;32m~/DragVideo/PTI/torch_utils/persistence.py:227\u001b[0m, in \u001b[0;36m_src_to_module\u001b[0;34m(src)\u001b[0m\n\u001b[1;32m    225\u001b[0m     _module_to_src_dict[module] \u001b[39m=\u001b[39m src\n\u001b[1;32m    226\u001b[0m     _src_to_module_dict[src] \u001b[39m=\u001b[39m module\n\u001b[0;32m--> 227\u001b[0m     exec(src, module\u001b[39m.\u001b[39;49m\u001b[39m__dict__\u001b[39;49m) \u001b[39m# pylint: disable=exec-used\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[39mreturn\u001b[39;00m module\n",
      "File \u001b[0;32m<string>:11\u001b[0m\n",
      "File \u001b[0;32m~/DragVideo/PTI/torch_utils/ops/filtered_lrelu.py:15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m bias_act\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m upfirdn2d\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m custom_ops\n",
      "File \u001b[0;32m~/DragVideo/PTI/torch_utils/ops/bias_act.py:17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdnnlib\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m custom_ops\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m misc\n\u001b[1;32m     20\u001b[0m \u001b[39m#----------------------------------------------------------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/DragVideo/PTI/torch_utils/custom_ops.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39muuid\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcpp_extension\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m#----------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m# Global options.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m verbosity \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbrief\u001b[39m\u001b[39m'\u001b[39m \u001b[39m# Verbosity level: 'none', 'brief', 'full'\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/stylegan3/lib/python3.9/site-packages/torch/utils/cpp_extension.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfile_baton\u001b[39;00m \u001b[39mimport\u001b[39;00m FileBaton\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_cpp_extension_versioner\u001b[39;00m \u001b[39mimport\u001b[39;00m ExtensionVersioner\n\u001b[0;32m---> 19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mhipify\u001b[39;00m \u001b[39mimport\u001b[39;00m hipify_python\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mhipify\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhipify_python\u001b[39;00m \u001b[39mimport\u001b[39;00m GeneratedFileCleaner\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Dict, List, Optional, Union, Tuple\n",
      "File \u001b[0;32m~/.conda/envs/stylegan3/lib/python3.9/site-packages/torch/utils/hipify/hipify_python.py:34\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m constants\n\u001b[0;32m---> 34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcuda_to_hip_mappings\u001b[39;00m \u001b[39mimport\u001b[39;00m CUDA_TO_HIP_MAPPINGS\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcuda_to_hip_mappings\u001b[39;00m \u001b[39mimport\u001b[39;00m MATH_TRANSPILATIONS\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Dict, List, Iterator, Optional\n",
      "File \u001b[0;32m~/.conda/envs/stylegan3/lib/python3.9/site-packages/torch/utils/hipify/cuda_to_hip_mappings.py:34\u001b[0m\n\u001b[1;32m     32\u001b[0m rocm_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mROCM_HOME\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mROCM_PATH\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m/opt/rocm\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 34\u001b[0m     rocm_path \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mcheck_output([\u001b[39m\"\u001b[39;49m\u001b[39mhipconfig\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m--rocmpath\u001b[39;49m\u001b[39m\"\u001b[39;49m])\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[39mexcept\u001b[39;00m subprocess\u001b[39m.\u001b[39mCalledProcessError:\n\u001b[1;32m     36\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWarning: hipconfig --rocmpath failed, assuming \u001b[39m\u001b[39m{\u001b[39;00mrocm_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/stylegan3/lib/python3.9/subprocess.py:424\u001b[0m, in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    421\u001b[0m         empty \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    422\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m empty\n\u001b[0;32m--> 424\u001b[0m \u001b[39mreturn\u001b[39;00m run(\u001b[39m*\u001b[39;49mpopenargs, stdout\u001b[39m=\u001b[39;49mPIPE, timeout\u001b[39m=\u001b[39;49mtimeout, check\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    425\u001b[0m            \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39mstdout\n",
      "File \u001b[0;32m~/.conda/envs/stylegan3/lib/python3.9/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    502\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstdout\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[1;32m    503\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstderr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[0;32m--> 505\u001b[0m \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39;49mpopenargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mas\u001b[39;00m process:\n\u001b[1;32m    506\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    507\u001b[0m         stdout, stderr \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39mcommunicate(\u001b[39minput\u001b[39m, timeout\u001b[39m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/.conda/envs/stylegan3/lib/python3.9/subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[1;32m    947\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_mode:\n\u001b[1;32m    948\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[1;32m    949\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m--> 951\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[1;32m    952\u001b[0m                         pass_fds, cwd, env,\n\u001b[1;32m    953\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[1;32m    954\u001b[0m                         p2cread, p2cwrite,\n\u001b[1;32m    955\u001b[0m                         c2pread, c2pwrite,\n\u001b[1;32m    956\u001b[0m                         errread, errwrite,\n\u001b[1;32m    957\u001b[0m                         restore_signals,\n\u001b[1;32m    958\u001b[0m                         gid, gids, uid, umask,\n\u001b[1;32m    959\u001b[0m                         start_new_session)\n\u001b[1;32m    960\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdin, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m~/.conda/envs/stylegan3/lib/python3.9/subprocess.py:1770\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1768\u001b[0m     fds_to_keep \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(pass_fds)\n\u001b[1;32m   1769\u001b[0m     fds_to_keep\u001b[39m.\u001b[39madd(errpipe_write)\n\u001b[0;32m-> 1770\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpid \u001b[39m=\u001b[39m _posixsubprocess\u001b[39m.\u001b[39;49mfork_exec(\n\u001b[1;32m   1771\u001b[0m             args, executable_list,\n\u001b[1;32m   1772\u001b[0m             close_fds, \u001b[39mtuple\u001b[39;49m(\u001b[39msorted\u001b[39;49m(\u001b[39mmap\u001b[39;49m(\u001b[39mint\u001b[39;49m, fds_to_keep))),\n\u001b[1;32m   1773\u001b[0m             cwd, env_list,\n\u001b[1;32m   1774\u001b[0m             p2cread, p2cwrite, c2pread, c2pwrite,\n\u001b[1;32m   1775\u001b[0m             errread, errwrite,\n\u001b[1;32m   1776\u001b[0m             errpipe_read, errpipe_write,\n\u001b[1;32m   1777\u001b[0m             restore_signals, start_new_session,\n\u001b[1;32m   1778\u001b[0m             gid, gids, uid, umask,\n\u001b[1;32m   1779\u001b[0m             preexec_fn)\n\u001b[1;32m   1780\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_child_created \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1782\u001b[0m     \u001b[39m# be sure the FD is closed no matter what\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os \n",
    "import sys\n",
    "root_dir = '/home/bean/DragVideo'\n",
    "os.chdir(f'{root_dir}/PTI')\n",
    "\n",
    "use_multi_id_training = True\n",
    "\n",
    "from scripts.run_pti import run_PTI\n",
    "model_id = run_PTI(use_wandb=False, use_multi_id_training=use_multi_id_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from configs import paths_config, hyperparameters, global_config\n",
    "from utils.align_data import pre_process_images\n",
    "from scripts.run_pti import run_PTI\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from scripts.latent_editor_wrapper import LatentEditorWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_generators(model_id, image_name):\n",
    "  with open(paths_config.stylegan2_ada_ffhq, 'rb') as f:\n",
    "    old_G = pickle.load(f)['G_ema'].cuda()\n",
    "\n",
    "  with open(f'{paths_config.checkpoints_dir}/model_{model_id}_{image_name}.pt', 'rb') as f_new:\n",
    "    new_G = torch.load(f_new).cuda()\n",
    "\n",
    "  return old_G, new_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_name = \"000\"\n",
    "\n",
    "# # /home/bean/DragVideo/DragGAN/PTI_results/checkpoints/model_ZEWLQSQSSQWA_000.pt\n",
    "# model_id = \"ZEWLQSQSSQWA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/bean/DragVideo//DragGAN/PTI_results/checkpoints/model_HCQDSNSTNNJM_multi_id.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m use_multi_id_training \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m      4\u001b[0m generator_type \u001b[39m=\u001b[39m paths_config\u001b[39m.\u001b[39mmulti_id_model_type \u001b[39mif\u001b[39;00m use_multi_id_training \u001b[39melse\u001b[39;00m image_name\n\u001b[0;32m----> 5\u001b[0m old_G, new_G \u001b[39m=\u001b[39m load_generators(model_id, generator_type)\n",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m, in \u001b[0;36mload_generators\u001b[0;34m(model_id, image_name)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(paths_config\u001b[39m.\u001b[39mstylegan2_ada_ffhq, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m   old_G \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(f)[\u001b[39m'\u001b[39m\u001b[39mG_ema\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m----> 5\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mpaths_config\u001b[39m.\u001b[39;49mcheckpoints_dir\u001b[39m}\u001b[39;49;00m\u001b[39m/model_\u001b[39;49m\u001b[39m{\u001b[39;49;00mmodel_id\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mimage_name\u001b[39m}\u001b[39;49;00m\u001b[39m.pt\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f_new:\n\u001b[1;32m      6\u001b[0m   new_G \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(f_new)\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m      8\u001b[0m \u001b[39mreturn\u001b[39;00m old_G, new_G\n",
      "File \u001b[0;32m~/.conda/envs/stylegan3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/bean/DragVideo//DragGAN/PTI_results/checkpoints/model_HCQDSNSTNNJM_multi_id.pt'"
     ]
    }
   ],
   "source": [
    "model_id = '/home/bean/DragVideo/Data_store/model_weights/sg3_3rdtime_weights/sg3-r-ffhq-1024_module.pt'\n",
    "use_multi_id_training = True\n",
    "\n",
    "generator_type = paths_config.multi_id_model_type if use_multi_id_training else image_name\n",
    "old_G, new_G = load_generators(model_id, generator_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_G' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 20\u001b[0m\n\u001b[1;32m     15\u001b[0m   tmp[\u001b[39m'\u001b[39m\u001b[39maugment_pipe\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     17\u001b[0m   \u001b[39m# with open(f'{paths_config.checkpoints_dir}/stylegan2_{model_id}.pkl', 'wb') as f:\u001b[39;00m\n\u001b[1;32m     18\u001b[0m   \u001b[39m#     pickle.dump(tmp, f)\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m export_updated_pickle(new_G,model_id)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_G' is not defined"
     ]
    }
   ],
   "source": [
    "#code from : https://github.com/danielroich/PTI/issues/26 , plus little bit modification\n",
    "\n",
    "def export_updated_pickle(new_G,model_id):\n",
    "  print(\"Exporting large updated pickle based off new generator and ffhq.pkl\")\n",
    "  with open(paths_config.stylegan2_ada_ffhq, 'rb') as f:\n",
    "    d = pickle.load(f)\n",
    "    old_G = d['G_ema'].cuda()\n",
    "    old_D = d['D'].eval().requires_grad_(False).cpu()\n",
    "\n",
    "  tmp = {}\n",
    "  tmp['G'] = old_G.eval().requires_grad_(False).cpu()\n",
    "  tmp['G_ema'] = new_G.eval().requires_grad_(False).cpu()\n",
    "  tmp['D'] = old_D\n",
    "  tmp['training_set_kwargs'] = None\n",
    "  tmp['augment_pipe'] = None\n",
    "\n",
    "  # with open(f'{paths_config.checkpoints_dir}/stylegan3_{model_id}.pkl', 'wb') as f:\n",
    "  #     pickle.dump(tmp, f)\n",
    "\n",
    "export_updated_pickle(new_G,model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ZEWLQSQSSQWA'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id # 'AXOCWYGCAEDY'for 10 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # .pt to .pkl file conversion\n",
    "\n",
    "# sg3_pt_file_path = '/home/bean/DragVideo/Data_store/model_weights/sg3_3rdtime_weights/sg3-r-ffhqu-1024.pt' #downloaded\n",
    "# # sg3_pt_file_path_full=\"/home/bean/DragVideo/Data_store/data/PTI_results/checkpoints/model_HCQDSNSTNNJM_multi_id.pt\"\n",
    "\n",
    "# with open(sg3_pt_file_path, 'rb') as f_new:\n",
    "#     weights = torch.load(f_new)#.cuda()\n",
    "\n",
    "# # with open(sg3_pt_file_path_full, 'rb') as f_new:\n",
    "# #     module = torch.load(f_new)#.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sg3_1024_pkl = \"/home/bean/DragVideo/PTI/pretrained_models/stylegan3-r-ffhq-1024x1024.pkl\"\n",
    "# with open(sg3_1024_pkl,'rb') as f:\n",
    "#     sg3_1024 = pickle.load(f)\n",
    "\n",
    "# torch.save(sg3_1024[\"G\"],'/home/bean/DragVideo/Data_store/model_weights/sg3_3rdtime_weights/sg3-r-ffhqu-1024_module.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting large updated pickle based off new generator and ffhq.pkl\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m       pickle\u001b[39m.\u001b[39mdump(tmp, f)\n\u001b[1;32m     18\u001b[0m model_id \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m3rdtime_test\u001b[39m\u001b[39m'\u001b[39m \n\u001b[0;32m---> 19\u001b[0m export_updated_pickle(new_G,model_id)\n",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m, in \u001b[0;36mexport_updated_pickle\u001b[0;34m(new_G, model_id)\u001b[0m\n\u001b[1;32m      8\u001b[0m tmp \u001b[39m=\u001b[39m {}\n\u001b[1;32m      9\u001b[0m tmp[\u001b[39m'\u001b[39m\u001b[39mG\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m old_G\u001b[39m.\u001b[39meval()\u001b[39m.\u001b[39mrequires_grad_(\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mcpu()\n\u001b[0;32m---> 10\u001b[0m tmp[\u001b[39m'\u001b[39m\u001b[39mG_ema\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m new_G\u001b[39m.\u001b[39;49meval()\u001b[39m.\u001b[39mrequires_grad_(\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mcpu()\n\u001b[1;32m     11\u001b[0m tmp[\u001b[39m'\u001b[39m\u001b[39mD\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m old_D\n\u001b[1;32m     12\u001b[0m tmp[\u001b[39m'\u001b[39m\u001b[39mtraining_set_kwargs\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "def export_updated_pickle(new_G,model_id):\n",
    "  print(\"Exporting large updated pickle based off new generator and ffhq.pkl\")\n",
    "  with open(paths_config.stylegan2_ada_ffhq, 'rb') as f:\n",
    "    d = pickle.load(f)\n",
    "    old_G = d['G_ema'].cuda()\n",
    "    old_D = d['D'].eval().requires_grad_(False).cpu()\n",
    "\n",
    "  tmp = {}\n",
    "  tmp['G'] = old_G.eval().requires_grad_(False).cpu()\n",
    "  tmp['G_ema'] = new_G.eval().requires_grad_(False).cpu()\n",
    "  tmp['D'] = old_D\n",
    "  tmp['training_set_kwargs'] = None\n",
    "  tmp['augment_pipe'] = None\n",
    "\n",
    "  with open(f'{paths_config.checkpoints_dir}/stylegan2_{model_id}.pkl', 'wb') as f:\n",
    "      pickle.dump(tmp, f)\n",
    "\n",
    "model_id = '3rdtime_test' \n",
    "export_updated_pickle(new_G,model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg3_3rdtime_pt = '/home/bean/DragVideo/Data_store/model_weights/sg3_3rdtime_weights/sg3-r-ffhq-1024_module.pt'\n",
    "use_multi_id_training = True\n",
    "sg3_1024_pkl = \"/home/bean/DragVideo/PTI/pretrained_models/stylegan3-r-ffhq-1024x1024.pkl\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sg3_1024_pkl, 'rb') as f:\n",
    "    old_G = pickle.load(f)['G_ema'].cuda()\n",
    "\n",
    "with open(sg3_3rdtime_pt, 'rb') as f_new:\n",
    "    new_G = torch.load(f_new).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sg3_1024_pkl, 'rb') as f:\n",
    "    d = pickle.load(f)\n",
    "    old_G = d['G_ema'].cuda()\n",
    "    old_D = d['D'].eval().requires_grad_(False).cpu()\n",
    "\n",
    "tmp = {}\n",
    "tmp['G'] = old_G.eval().requires_grad_(False).cpu()\n",
    "tmp['G_ema'] = new_G.eval().requires_grad_(False).cpu()\n",
    "tmp['D'] = old_D\n",
    "tmp['training_set_kwargs'] = None\n",
    "tmp['augment_pipe'] = None\n",
    "\n",
    "with open('/home/bean/DragVideo/Data_store/model_weights/sg3_3rdtime_weights/sg3-r-ffhq-1024_module.pkl', 'wb') as f:\n",
    "    pickle.dump(tmp, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg3u_3rdtime_pt = '/home/bean/DragVideo/Data_store/model_weights/sg3_3rdtime_weights/sg3-r-ffhqu-1024_module.pt'\n",
    "use_multi_id_training = True\n",
    "sg3_1024_pkl = \"/home/bean/DragVideo/PTI/pretrained_models/stylegan3-r-ffhq-1024x1024.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sg3_1024_pkl, 'rb') as f:\n",
    "    old_G = pickle.load(f)['G_ema'].cuda()\n",
    "\n",
    "with open(sg3u_3rdtime_pt, 'rb') as f_new:\n",
    "    new_G = torch.load(f_new).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sg3_1024_pkl, 'rb') as f:\n",
    "    d = pickle.load(f)\n",
    "    old_G = d['G_ema'].cuda()\n",
    "    old_D = d['D'].eval().requires_grad_(False).cpu()\n",
    "\n",
    "tmp = {}\n",
    "tmp['G'] = old_G.eval().requires_grad_(False).cpu()\n",
    "tmp['G_ema'] = new_G.eval().requires_grad_(False).cpu()\n",
    "tmp['D'] = old_D\n",
    "tmp['training_set_kwargs'] = None\n",
    "tmp['augment_pipe'] = None\n",
    "\n",
    "with open('/home/bean/DragVideo/Data_store/model_weights/sg3_3rdtime_weights/sg3-r-ffhqu-1024_module.pkl', 'wb') as f:\n",
    "    pickle.dump(tmp, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e4e_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
