{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directions to run \n",
    "outside the docker \n",
    "env: sg3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a directory for new experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "# set environment variables to make only 1 GPU visible, and select it\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "# check if GPU is visible\n",
    "import torch\n",
    "torch.cuda.device_count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DRAGVIDEO_ROOT_PATH = \"/Ext_4T_SSD/ASHOK/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_config = {\n",
    "    \"EXP_NAME\": \"exp_01_pti_1_inv_1\",\n",
    "    \"e4e\": f\"{DRAGVIDEO_ROOT_PATH}DragVideo/DragGAN/_PTI/pretrained_models/e4e_ffhq_encode.pt\",\n",
    "    \"stylegan2_ada_ffhq\": f\"{DRAGVIDEO_ROOT_PATH}DragVideo/DragGAN/_PTI/pretrained_models/ffhq.pkl\",\n",
    "    \"video_path\":  f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/OLD/original_videos/person_speaking_original.mp4\",\n",
    "    \"model_name\" : \"stylegan2\",\n",
    "    \"n_frames\" : 1,\n",
    "    \"IMAGE_SIZE\": 1024,\n",
    "    \"N_STEPS_in_draggan\": \"1\",\n",
    "    \n",
    "\n",
    "}\n",
    "\n",
    "env_config = {\n",
    "    # \"DragGAN_dir\": f\"{DRAGVIDEO_ROOT_PATH}DragVideo/DragGAN\",\n",
    "    # \"Experiment_base_path\":f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/experiments/' ,\n",
    "    # \"dummy_config_path\" : f\"{DRAGVIDEO_ROOT_PATH}DragVideo/DragGAN/_PTI/configs/dummy',\n",
    "\n",
    "    \n",
    "    # for outside the container\n",
    "    \"DragGAN_dir\": \"/Ext_4T_SSD/ASHOK/DragVideo/DragGAN\",\n",
    "    \"Experiment_base_path\":'/Ext_4T_SSD/ASHOK/DragVideo/Data_store/experiments/' ,\n",
    "    \"init_exp_dir_shell_path\": \"/Ext_4T_SSD/ASHOK/DragVideo/DragGAN/_PTI/init_datadirs.sh\",\n",
    "    \"dummy_config_path\" : '/Ext_4T_SSD/ASHOK/DragVideo/DragGAN/_PTI/configs/dummy',\n",
    "\n",
    "}\n",
    "\n",
    "#hyper parameters in PTI\n",
    "hyper_config = {\n",
    "    \"max_pti_steps\": 1,#500,\n",
    "    \"first_inv_steps\": 1,#00,\n",
    "    \"max_images_to_invert\": 200,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment directory already exists\n"
     ]
    }
   ],
   "source": [
    "from run_utils import *\n",
    "\n",
    "# create experiment data folder structure\n",
    "Experiment_name = lazy_config[\"EXP_NAME\"]\n",
    "Experiment_base_path = env_config[\"Experiment_base_path\"]\n",
    "Experiment_path = os.path.join(Experiment_base_path, Experiment_name)\n",
    "\n",
    "init_experiment_dir(Experiment_name,Experiment_base_path,shell_script_path=env_config[\"init_exp_dir_shell_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set paths for e4e, stylegan used in PTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy paths_config overwrites the paths_config.py\n",
    "# dummy_config_path = f\"{DRAGVIDEO_ROOT_PATH}DragVideo/DragGAN/_PTI/configs/dummy'\n",
    "add_dummy_config_from_dict(\"hyperparameters.py\", hyper_config,ROOT_PATH=env_config[\"dummy_config_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change path configs , hyperparameters \n",
    "paths_config_dict = {\n",
    "    #pretrained models\n",
    "    \"e4e\": lazy_config[\"e4e\"],\n",
    "    \"stylegan2_ada_ffhq\": lazy_config[\"stylegan2_ada_ffhq\"],\n",
    "    \n",
    "    # to store tuned stylegan weights\n",
    "    \"checkpoints_dir\": os.path.join(Experiment_path,'tuned_SG'),\n",
    "    # to store latents\n",
    "    \"embedding_base_dir\": os.path.join(Experiment_path,'latents'),\n",
    "    # aligned / processed images\n",
    "    \"input_data_path\": os.path.join(Experiment_path,'aligned'),\n",
    "}\n",
    "\n",
    "add_dummy_config_from_dict(\"paths_config.py\", paths_config_dict,ROOT_PATH=env_config[\"dummy_config_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating.../Ext_4T_SSD/ASHOK/DragVideo/Data_store/experiments/exp_01_pti_1_inv_1/raw/000.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "from importlib.machinery import SourceFileLoader\n",
    "# imports the module from the given path\n",
    "video_utils = SourceFileLoader(\"video_utils\",\"../utils_draggan/video_utils.py\").load_module()\n",
    "raw_path = os.path.join(Experiment_path, \"raw\")\n",
    "from utils.align_data import pre_process_images\n",
    "\n",
    "video_utils.extract_frames(lazy_config['video_path'], raw_path,n_frames=lazy_config['n_frames'])\n",
    "pre_process_images(raw_path, IMAGE_SIZE=lazy_config['IMAGE_SIZE']) # o/p: config.input_data_path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /Ext_4T_SSD/ASHOK/DragVideo/env/sg3/lib/python3.9/site-packages/lpips/weights/v0.1/alex.pth\n",
      "current_directory:  /Ext_4T_SSD/ASHOK/DragVideo/DragGAN/_PTI\n",
      "current_directory:  /Ext_4T_SSD/ASHOK/DragVideo/DragGAN/_PTI\n",
      "torch.Size([3, 1024, 1024]) 3 1024 1024\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  7.07it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from utils.align_data import pre_process_images\n",
    "from scripts.run_pti import run_PTI\n",
    "\n",
    "from run_utils_2 import load_generators,export_updated_pickle\n",
    "from configs import paths_config\n",
    "\n",
    "use_multi_id_training = True\n",
    "model_id = run_PTI(use_wandb=False, use_multi_id_training=use_multi_id_training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting large updated pickle based off new generator and ffhq.pkl\n",
      "/Ext_4T_SSD/ASHOK/DragVideo/Data_store/experiments/exp_01_pti_1_inv_1/tuned_SG/stylegan2_GIFNUZUFBIPS.pkl\n"
     ]
    }
   ],
   "source": [
    "use_multi_id_training = True\n",
    "\n",
    "generator_type =paths_config.multi_id_model_type if use_multi_id_training else image_name\n",
    "old_G, new_G = load_generators(model_id, generator_type)\n",
    "sg_tuned_pkl = export_updated_pickle(new_G,model_id,name = lazy_config[\"model_name\"])\n",
    "\n",
    "print(sg_tuned_pkl) # 'QBUXQCXZGWET'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "landmark_path:  /Ext_4T_SSD/ASHOK/DragVideo/Data_store/experiments/exp_01_pti_1_inv_1/landmarks/000.pkl\n"
     ]
    }
   ],
   "source": [
    "#get landmarks\n",
    "landmark_path = f\"{DRAGVIDEO_ROOT_PATH}DragVideo/DragGAN/_facial-landmarks-recognition\"\n",
    "os.chdir(landmark_path)\n",
    "\n",
    "from main import landmarks, dict_landmarks,show_landmarks,get_landmarks_dir\n",
    "\n",
    "# to store landmarks\n",
    "landmarks_dir =  os.path.join(Experiment_path,'landmarks')\n",
    "processed_images_dir =  os.path.join(Experiment_path,'aligned')\n",
    "\n",
    "# generate landmarks for all images in processed_images_dir\n",
    "get_landmarks_dir(processed_images_dir,landmarks_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intiating global state....\n",
      "calling init_images......\n",
      "Loading \"/Ext_4T_SSD/ASHOK/DragVideo/Data_store/experiments/exp_01_pti_1_inv_1/tuned_SG/stylegan2_GIFNUZUFBIPS.pkl\"... Done.\n",
      "()\n",
      "{'z_dim': 512, 'c_dim': 0, 'w_dim': 512, 'img_resolution': 1024, 'img_channels': 3, 'mapping_kwargs': {'num_layers': 8, 'embed_features': None, 'layer_features': None, 'activation': 'lrelu', 'lr_multiplier': 0.01, 'w_avg_beta': 0.995}, 'synthesis_kwargs': {'channel_base': 32768, 'channel_max': 512, 'num_fp16_res': 4, 'conv_clamp': 256, 'architecture': 'skip', 'resample_filter': [1, 3, 3, 1], 'use_noise': True, 'activation': 'lrelu'}}\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "Running with:\n",
      "    Source: [array([258, 489]), array([262, 566]), array([269, 642]), array([277, 720]), array([301, 793]), array([339, 861]), array([383, 927]), array([437, 986]), array([ 507, 1003]), array([580, 988]), array([641, 936]), array([694, 876]), array([740, 811]), array([770, 739]), array([782, 659]), array([793, 578]), array([804, 496]), array([290, 448]), array([311, 401]), array([359, 375]), array([413, 373]), array([464, 389]), array([554, 382]), array([609, 368]), array([666, 373]), array([715, 403]), array([742, 450]), array([506, 465]), array([503, 525]), array([500, 583]), array([498, 643]), array([441, 668]), array([468, 683]), array([500, 696]), array([536, 682]), array([568, 669]), array([357, 488]), array([383, 477]), array([412, 477]), array([442, 484]), array([413, 486]), array([385, 488]), array([582, 484]), array([610, 476]), array([639, 478]), array([666, 488]), array([637, 488]), array([610, 486]), array([399, 766]), array([432, 754]), array([471, 749]), array([504, 758]), array([538, 750]), array([582, 755]), array([624, 768]), array([587, 831]), array([542, 856]), array([505, 860]), array([469, 855]), array([429, 829]), array([415, 770]), array([471, 768]), array([504, 771]), array([538, 768]), array([608, 772]), array([541, 821]), array([506, 825]), array([471, 819])]\n",
      "    Target: [array([208, 489]), array([212, 566]), array([219, 642]), array([227, 720]), array([251, 793]), array([289, 861]), array([383, 877]), array([437, 936]), array([507, 953]), array([580, 938]), array([641, 886]), array([744, 876]), array([790, 811]), array([820, 739]), array([832, 659]), array([843, 578]), array([854, 496]), array([290, 448]), array([311, 401]), array([359, 375]), array([413, 373]), array([464, 389]), array([554, 382]), array([609, 368]), array([666, 373]), array([715, 403]), array([742, 450]), array([506, 465]), array([503, 525]), array([500, 583]), array([498, 643]), array([500, 696]), array([500, 696]), array([500, 696]), array([500, 696]), array([500, 696]), array([357, 488]), array([383, 477]), array([412, 477]), array([442, 484]), array([413, 486]), array([385, 488]), array([582, 484]), array([610, 476]), array([639, 478]), array([666, 488]), array([637, 488]), array([610, 486]), array([399, 766]), array([432, 754]), array([471, 749]), array([504, 758]), array([538, 750]), array([582, 755]), array([624, 768]), array([587, 831]), array([542, 856]), array([505, 860]), array([469, 855]), array([429, 829]), array([415, 770]), array([471, 768]), array([504, 771]), array([538, 768]), array([608, 772]), array([541, 821]), array([506, 825]), array([471, 819])]\n",
      "p_to_opt: [[489, 258], [566, 262], [642, 269], [720, 277], [793, 301], [861, 339], [927, 383], [986, 437], [1003, 507], [988, 580], [936, 641], [876, 694], [811, 740], [739, 770], [659, 782], [578, 793], [496, 804], [448, 290], [401, 311], [375, 359], [373, 413], [389, 464], [382, 554], [368, 609], [373, 666], [403, 715], [450, 742], [465, 506], [525, 503], [583, 500], [643, 498], [668, 441], [683, 468], [696, 500], [682, 536], [669, 568], [488, 357], [477, 383], [477, 412], [484, 442], [486, 413], [488, 385], [484, 582], [476, 610], [478, 639], [488, 666], [488, 637], [486, 610], [766, 399], [754, 432], [749, 471], [758, 504], [750, 538], [755, 582], [768, 624], [831, 587], [856, 542], [860, 505], [855, 469], [829, 429], [770, 415], [768, 471], [771, 504], [768, 538], [772, 608], [821, 541], [825, 506], [819, 471]]\n",
      "t_to_opt: [[489, 208], [566, 212], [642, 219], [720, 227], [793, 251], [861, 289], [877, 383], [936, 437], [953, 507], [938, 580], [886, 641], [876, 744], [811, 790], [739, 820], [659, 832], [578, 843], [496, 854], [448, 290], [401, 311], [375, 359], [373, 413], [389, 464], [382, 554], [368, 609], [373, 666], [403, 715], [450, 742], [465, 506], [525, 503], [583, 500], [643, 498], [696, 500], [696, 500], [696, 500], [696, 500], [696, 500], [488, 357], [477, 383], [477, 412], [484, 442], [486, 413], [488, 385], [484, 582], [476, 610], [478, 639], [488, 666], [488, 637], [486, 610], [766, 399], [754, 432], [749, 471], [758, 504], [750, 538], [755, 582], [768, 624], [831, 587], [856, 542], [860, 505], [855, 469], [829, 429], [770, 415], [768, 471], [771, 504], [768, 538], [772, 608], [821, 541], [825, 506], [819, 471]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Ext_4T_SSD/ASHOK/DragVideo/env/sg3/lib/python3.9/site-packages/torch/nn/functional.py:3609: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Source:\n",
      "    [258, 489]\n",
      "    [262, 566]\n",
      "    [269, 642]\n",
      "    [277, 720]\n",
      "    [301, 793]\n",
      "    [339, 861]\n",
      "    [383, 927]\n",
      "    [437, 986]\n",
      "    [507, 1003]\n",
      "    [580, 988]\n",
      "    [641, 936]\n",
      "    [694, 876]\n",
      "    [740, 811]\n",
      "    [770, 739]\n",
      "    [782, 659]\n",
      "    [793, 578]\n",
      "    [804, 496]\n",
      "    [290, 448]\n",
      "    [311, 401]\n",
      "    [359, 375]\n",
      "    [413, 373]\n",
      "    [464, 389]\n",
      "    [554, 382]\n",
      "    [609, 368]\n",
      "    [666, 373]\n",
      "    [715, 403]\n",
      "    [742, 450]\n",
      "    [506, 465]\n",
      "    [503, 525]\n",
      "    [500, 583]\n",
      "    [498, 643]\n",
      "    [441, 668]\n",
      "    [468, 683]\n",
      "    [500, 696]\n",
      "    [536, 682]\n",
      "    [568, 669]\n",
      "    [357, 488]\n",
      "    [383, 477]\n",
      "    [412, 477]\n",
      "    [442, 484]\n",
      "    [413, 486]\n",
      "    [385, 488]\n",
      "    [582, 484]\n",
      "    [610, 476]\n",
      "    [639, 478]\n",
      "    [666, 488]\n",
      "    [637, 488]\n",
      "    [610, 486]\n",
      "    [399, 766]\n",
      "    [432, 754]\n",
      "    [471, 749]\n",
      "    [504, 758]\n",
      "    [538, 750]\n",
      "    [582, 755]\n",
      "    [624, 768]\n",
      "    [587, 831]\n",
      "    [542, 856]\n",
      "    [505, 860]\n",
      "    [469, 855]\n",
      "    [429, 829]\n",
      "    [415, 770]\n",
      "    [471, 768]\n",
      "    [504, 771]\n",
      "    [538, 768]\n",
      "    [608, 772]\n",
      "    [541, 821]\n",
      "    [506, 825]\n",
      "    [471, 819]\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(env_config[\"DragGAN_dir\"])\n",
    "import subprocess\n",
    "subprocess.call(['python', 'run_dragvideo.py', '--Experiment_path', Experiment_path, '--N_STEPS', lazy_config[\"N_STEPS_in_draggan\"], '--CHECKPOINT_PATH', sg_tuned_pkl])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ala' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ala\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ala' is not defined"
     ]
    }
   ],
   "source": [
    "ala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/danielroich/PTI\n",
    "\n",
    "# run below commands from /PTI/ \n",
    "# export PYTHONPATH=$PYTHONPATH:$PWD\n",
    "\n",
    "# change path inside it.\n",
    "# python utils/align_data.py\n",
    "\n",
    "# path_ = f\"{DRAGVIDEO_ROOT_PATH}DragVideo/PTI\"\n",
    "# import os \n",
    "# os.chdir(path_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os \n",
    "# dir = \"/workspace/PTI/data/raw_images\"\n",
    "# # it has images from 0 to 400 .jpeg \n",
    "# # rename them so that all are 3 digits\n",
    "# for i in range(400):\n",
    "#     if i < 10:\n",
    "#         os.rename(dir + \"/\" + str(i) + \".jpg\", dir + \"/00\" + str(i) + \".jpg\")\n",
    "#     elif i < 100:\n",
    "#         os.rename(dir + \"/\" + str(i) + \".jpg\", dir + \"/0\" + str(i) + \".jpg\")\n",
    "#     else:\n",
    "#         continue\n",
    "#         # os.rename(dir + \"/\" + str(i) + \".jpeg\", dir + \"/\" + str(i) + \".jpeg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/bean/DragVideo/PTI'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[1;32m      3\u001b[0m root_dir \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/home/bean/DragVideo\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m os\u001b[39m.\u001b[39;49mchdir(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mroot_dir\u001b[39m}\u001b[39;49;00m\u001b[39m/PTI\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      6\u001b[0m use_multi_id_training \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscripts\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrun_pti\u001b[39;00m \u001b[39mimport\u001b[39;00m run_PTI\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/bean/DragVideo/PTI'"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import sys\n",
    "root_dir = f\"{DRAGVIDEO_ROOT_PATH}DragVideo'\n",
    "os.chdir(f'{root_dir}/PTI')\n",
    "\n",
    "use_multi_id_training = True\n",
    "\n",
    "from scripts.run_pti import run_PTI\n",
    "model_id = run_PTI(use_wandb=False, use_multi_id_training=use_multi_id_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from configs import paths_config, hyperparameters, global_config\n",
    "from utils.align_data import pre_process_images\n",
    "from scripts.run_pti import run_PTI\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from scripts.latent_editor_wrapper import LatentEditorWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_generators(model_id, image_name):\n",
    "  with open(paths_config.stylegan2_ada_ffhq, 'rb') as f:\n",
    "    old_G = pickle.load(f)['G_ema'].cuda()\n",
    "\n",
    "  with open(f'{paths_config.checkpoints_dir}/model_{model_id}_{image_name}.pt', 'rb') as f_new:\n",
    "    new_G = torch.load(f_new).cuda()\n",
    "\n",
    "  return old_G, new_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_name = \"000\"\n",
    "\n",
    "# # /home/bean/DragVideo/DragGAN/PTI_results/checkpoints/model_ZEWLQSQSSQWA_000.pt\n",
    "# model_id = \"ZEWLQSQSSQWA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/model_weights/sg3_3rdtime_weights/sg3-r-ffhq-1024_module.pt'\n",
    "use_multi_id_training = True\n",
    "\n",
    "generator_type = paths_config.multi_id_model_type if use_multi_id_training else image_name\n",
    "old_G, new_G = load_generators(model_id, generator_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code from : https://github.com/danielroich/PTI/issues/26 , plus little bit modification\n",
    "\n",
    "def export_updated_pickle(new_G,model_id):\n",
    "  print(\"Exporting large updated pickle based off new generator and ffhq.pkl\")\n",
    "  with open(paths_config.stylegan2_ada_ffhq, 'rb') as f:\n",
    "    d = pickle.load(f)\n",
    "    old_G = d['G_ema'].cuda()\n",
    "    old_D = d['D'].eval().requires_grad_(False).cpu()\n",
    "\n",
    "  tmp = {}\n",
    "  tmp['G'] = old_G.eval().requires_grad_(False).cpu()\n",
    "  tmp['G_ema'] = new_G.eval().requires_grad_(False).cpu()\n",
    "  tmp['D'] = old_D\n",
    "  tmp['training_set_kwargs'] = None\n",
    "  tmp['augment_pipe'] = None\n",
    "\n",
    "  # with open(f'{paths_config.checkpoints_dir}/stylegan3_{model_id}.pkl', 'wb') as f:\n",
    "  #     pickle.dump(tmp, f)\n",
    "\n",
    "export_updated_pickle(new_G,model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ZEWLQSQSSQWA'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id # 'AXOCWYGCAEDY'for 10 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # .pt to .pkl file conversion\n",
    "\n",
    "# sg3_pt_file_path = f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/model_weights/sg3_3rdtime_weights/sg3-r-ffhqu-1024.pt' #downloaded\n",
    "# # sg3_pt_file_path_full=f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/data/PTI_results/checkpoints/model_HCQDSNSTNNJM_multi_id.pt\"\n",
    "\n",
    "# with open(sg3_pt_file_path, 'rb') as f_new:\n",
    "#     weights = torch.load(f_new)#.cuda()\n",
    "\n",
    "# # with open(sg3_pt_file_path_full, 'rb') as f_new:\n",
    "# #     module = torch.load(f_new)#.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sg3_1024_pkl = f\"{DRAGVIDEO_ROOT_PATH}DragVideo/PTI/pretrained_models/stylegan3-r-ffhq-1024x1024.pkl\"\n",
    "# with open(sg3_1024_pkl,'rb') as f:\n",
    "#     sg3_1024 = pickle.load(f)\n",
    "\n",
    "# torch.save(sg3_1024[\"G\"],f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/model_weights/sg3_3rdtime_weights/sg3-r-ffhqu-1024_module.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_updated_pickle(new_G,model_id):\n",
    "  print(\"Exporting large updated pickle based off new generator and ffhq.pkl\")\n",
    "  with open(paths_config.stylegan2_ada_ffhq, 'rb') as f:\n",
    "    d = pickle.load(f)\n",
    "    old_G = d['G_ema'].cuda()\n",
    "    old_D = d['D'].eval().requires_grad_(False).cpu()\n",
    "\n",
    "  tmp = {}\n",
    "  tmp['G'] = old_G.eval().requires_grad_(False).cpu()\n",
    "  tmp['G_ema'] = new_G.eval().requires_grad_(False).cpu()\n",
    "  tmp['D'] = old_D\n",
    "  tmp['training_set_kwargs'] = None\n",
    "  tmp['augment_pipe'] = None\n",
    "\n",
    "  with open(f'{paths_config.checkpoints_dir}/stylegan2_{model_id}.pkl', 'wb') as f:\n",
    "      pickle.dump(tmp, f)\n",
    "\n",
    "model_id = '3rdtime_test' \n",
    "export_updated_pickle(new_G,model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg3_3rdtime_pt = f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/model_weights/sg3_3rdtime_weights/sg3-r-ffhq-1024_module.pt'\n",
    "use_multi_id_training = True\n",
    "sg3_1024_pkl = f\"{DRAGVIDEO_ROOT_PATH}DragVideo/PTI/pretrained_models/stylegan3-r-ffhq-1024x1024.pkl\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sg3_1024_pkl, 'rb') as f:\n",
    "    old_G = pickle.load(f)['G_ema'].cuda()\n",
    "\n",
    "with open(sg3_3rdtime_pt, 'rb') as f_new:\n",
    "    new_G = torch.load(f_new).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sg3_1024_pkl, 'rb') as f:\n",
    "    d = pickle.load(f)\n",
    "    old_G = d['G_ema'].cuda()\n",
    "    old_D = d['D'].eval().requires_grad_(False).cpu()\n",
    "\n",
    "tmp = {}\n",
    "tmp['G'] = old_G.eval().requires_grad_(False).cpu()\n",
    "tmp['G_ema'] = new_G.eval().requires_grad_(False).cpu()\n",
    "tmp['D'] = old_D\n",
    "tmp['training_set_kwargs'] = None\n",
    "tmp['augment_pipe'] = None\n",
    "\n",
    "with open(f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/model_weights/sg3_3rdtime_weights/sg3-r-ffhq-1024_module.pkl', 'wb') as f:\n",
    "    pickle.dump(tmp, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg3u_3rdtime_pt = f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/model_weights/sg3_3rdtime_weights/sg3-r-ffhqu-1024_module.pt'\n",
    "use_multi_id_training = True\n",
    "sg3_1024_pkl = f\"{DRAGVIDEO_ROOT_PATH}DragVideo/PTI/pretrained_models/stylegan3-r-ffhq-1024x1024.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sg3_1024_pkl, 'rb') as f:\n",
    "    old_G = pickle.load(f)['G_ema'].cuda()\n",
    "\n",
    "with open(sg3u_3rdtime_pt, 'rb') as f_new:\n",
    "    new_G = torch.load(f_new).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sg3_1024_pkl, 'rb') as f:\n",
    "    d = pickle.load(f)\n",
    "    old_G = d['G_ema'].cuda()\n",
    "    old_D = d['D'].eval().requires_grad_(False).cpu()\n",
    "\n",
    "tmp = {}\n",
    "tmp['G'] = old_G.eval().requires_grad_(False).cpu()\n",
    "tmp['G_ema'] = new_G.eval().requires_grad_(False).cpu()\n",
    "tmp['D'] = old_D\n",
    "tmp['training_set_kwargs'] = None\n",
    "tmp['augment_pipe'] = None\n",
    "\n",
    "with open(f\"{DRAGVIDEO_ROOT_PATH}DragVideo/Data_store/model_weights/sg3_3rdtime_weights/sg3-r-ffhqu-1024_module.pkl', 'wb') as f:\n",
    "    pickle.dump(tmp, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
