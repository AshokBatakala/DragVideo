{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/home/bean/.conda/envs/stylegan3/lib/python3.9/site-packages/torch/lib/libc10_cuda.so: undefined symbol: cudaMemPoolSetAttribute, version libcudart.so.11.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/stylegan3/lib/python3.9/site-packages/torch/__init__.py:229\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[39mif\u001b[39;00m USE_GLOBAL_DEPS:\n\u001b[1;32m    228\u001b[0m         _load_global_deps()\n\u001b[0;32m--> 229\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_C\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F403\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39m# Appease the type checker; ordinarily this binding is inserted by the\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[39m# torch._C module initialization code in C\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m TYPE_CHECKING:\n",
      "\u001b[0;31mImportError\u001b[0m: /home/bean/.conda/envs/stylegan3/lib/python3.9/site-packages/torch/lib/libc10_cuda.so: undefined symbol: cudaMemPoolSetAttribute, version libcudart.so.11.0"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = \"/workspace/\"\n",
    "os.chdir(path)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PTI.utils.alignment import get_landmark, align_face\n",
    "import dlib\n",
    "from PTI.configs import paths_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"/workspace/PTI/data/raw_images/000.jpg\"\n",
    "predictor = dlib.shape_predictor(paths_config.dlib)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import scipy\n",
    "import scipy.ndimage\n",
    "import dlib\n",
    "\n",
    "\n",
    "def get_landmark(filepath, predictor):\n",
    "    \"\"\"get landmark with dlib\n",
    "    :return: np.array shape=(68, 2)\n",
    "    \"\"\"\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "    img = dlib.load_rgb_image(filepath)\n",
    "    dets = detector(img, 1)\n",
    "\n",
    "    for k, d in enumerate(dets):\n",
    "        shape = predictor(img, d)\n",
    "\n",
    "    t = list(shape.parts())\n",
    "    a = []\n",
    "    for tt in t:\n",
    "        a.append([tt.x, tt.y])\n",
    "    lm = np.array(a)\n",
    "    return lm\n",
    "\n",
    "\n",
    "def align_face(filepath, predictor, output_size):\n",
    "    \"\"\"\n",
    "    :param filepath: str\n",
    "    :return: PIL Image\n",
    "    \"\"\"\n",
    "\n",
    "    lm = get_landmark(filepath, predictor)\n",
    "\n",
    "    lm_chin = lm[0: 17]  # left-right\n",
    "    lm_eyebrow_left = lm[17: 22]  # left-right\n",
    "    lm_eyebrow_right = lm[22: 27]  # left-right\n",
    "    lm_nose = lm[27: 31]  # top-down\n",
    "    lm_nostrils = lm[31: 36]  # top-down\n",
    "    lm_eye_left = lm[36: 42]  # left-clockwise\n",
    "    lm_eye_right = lm[42: 48]  # left-clockwise\n",
    "    lm_mouth_outer = lm[48: 60]  # left-clockwise\n",
    "    lm_mouth_inner = lm[60: 68]  # left-clockwise\n",
    "\n",
    "    # Calculate auxiliary vectors.\n",
    "    eye_left = np.mean(lm_eye_left, axis=0)\n",
    "    eye_right = np.mean(lm_eye_right, axis=0)\n",
    "    eye_avg = (eye_left + eye_right) * 0.5\n",
    "    eye_to_eye = eye_right - eye_left\n",
    "    mouth_left = lm_mouth_outer[0]\n",
    "    mouth_right = lm_mouth_outer[6]\n",
    "    mouth_avg = (mouth_left + mouth_right) * 0.5\n",
    "    eye_to_mouth = mouth_avg - eye_avg\n",
    "\n",
    "    # Choose oriented crop rectangle.\n",
    "    x = eye_to_eye - np.flipud(eye_to_mouth) * [-1, 1]\n",
    "    x /= np.hypot(*x)\n",
    "    x *= max(np.hypot(*eye_to_eye) * 2.0, np.hypot(*eye_to_mouth) * 1.8)\n",
    "    y = np.flipud(x) * [-1, 1]\n",
    "    c = eye_avg + eye_to_mouth * 0.1\n",
    "    quad = np.stack([c - x - y, c - x + y, c + x + y, c + x - y])\n",
    "\n",
    "    qsize = np.hypot(*x) * 2\n",
    "\n",
    "    # read image\n",
    "    img = PIL.Image.open(filepath)\n",
    "\n",
    "    transform_size = output_size\n",
    "    enable_padding = True\n",
    "\n",
    "    # Shrink.\n",
    "    shrink = int(np.floor(qsize / output_size * 0.5))\n",
    "    if shrink > 1:\n",
    "        rsize = (int(np.rint(float(img.size[0]) / shrink)), int(np.rint(float(img.size[1]) / shrink)))\n",
    "        img = img.resize(rsize, PIL.Image.ANTIALIAS)\n",
    "        quad /= shrink\n",
    "        qsize /= shrink\n",
    "\n",
    "    # Crop.\n",
    "    border = max(int(np.rint(qsize * 0.1)), 3)\n",
    "    crop = (int(np.floor(min(quad[:, 0]))), int(np.floor(min(quad[:, 1]))), int(np.ceil(max(quad[:, 0]))),\n",
    "            int(np.ceil(max(quad[:, 1]))))\n",
    "    crop = (max(crop[0] - border, 0), max(crop[1] - border, 0), min(crop[2] + border, img.size[0]),\n",
    "            min(crop[3] + border, img.size[1]))\n",
    "    if crop[2] - crop[0] < img.size[0] or crop[3] - crop[1] < img.size[1]:\n",
    "        img = img.crop(crop)\n",
    "        quad -= crop[0:2]\n",
    "\n",
    "\n",
    "    # Pad.\n",
    "    pad = (int(np.floor(min(quad[:, 0]))), int(np.floor(min(quad[:, 1]))), int(np.ceil(max(quad[:, 0]))),\n",
    "           int(np.ceil(max(quad[:, 1]))))\n",
    "    pad = (max(-pad[0] + border, 0), max(-pad[1] + border, 0), max(pad[2] - img.size[0] + border, 0),\n",
    "           max(pad[3] - img.size[1] + border, 0))\n",
    "    yield border, crop, pad, qsize, quad\n",
    "\n",
    "    if enable_padding and max(pad) > border - 4:\n",
    "        pad = np.maximum(pad, int(np.rint(qsize * 0.3)))\n",
    "        img = np.pad(np.float32(img), ((pad[1], pad[3]), (pad[0], pad[2]), (0, 0)), 'reflect')\n",
    "        h, w, _ = img.shape\n",
    "        y, x, _ = np.ogrid[:h, :w, :1]\n",
    "        mask = np.maximum(1.0 - np.minimum(np.float32(x) / pad[0], np.float32(w - 1 - x) / pad[2]),\n",
    "                          1.0 - np.minimum(np.float32(y) / pad[1], np.float32(h - 1 - y) / pad[3]))\n",
    "        blur = qsize * 0.02\n",
    "        img += (scipy.ndimage.gaussian_filter(img, [blur, blur, 0]) - img) * np.clip(mask * 3.0 + 1.0, 0.0, 1.0)\n",
    "        img += (np.median(img, axis=(0, 1)) - img) * np.clip(mask, 0.0, 1.0)\n",
    "        img = PIL.Image.fromarray(np.uint8(np.clip(np.rint(img), 0, 255)), 'RGB')\n",
    "        quad += pad[:2]\n",
    "\n",
    "\n",
    "    # Transform.\n",
    "    img = img.transform((transform_size, transform_size), PIL.Image.QUAD, (quad + 0.5).flatten(), PIL.Image.BILINEAR)\n",
    "    if output_size < transform_size:\n",
    "        img = img.resize((output_size, output_size), PIL.Image.ANTIALIAS)\n",
    "\n",
    "    # Return aligned image.\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = align_face(image_path,predictor,120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-0f775be18b9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mborder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 1)"
     ]
    }
   ],
   "source": [
    "border,crop,q_size,quad = list(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e4e_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
